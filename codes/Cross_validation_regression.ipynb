{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936617da-a225-40c5-a6a0-dca31a7dbe03",
   "metadata": {},
   "source": [
    "# **Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7cbb8-5567-4777-90f3-b8fc77e023af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import oddt\n",
    "from oddt.fingerprints import PLEC\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import parallel_backend\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import deepchem as dc\n",
    "from deepchem.utils import download_url, load_from_disk\n",
    "from deepchem.utils.vina_utils import prepare_inputs\n",
    "from deepchem.models import AtomicConvModel\n",
    "from deepchem.feat import RdkitGridFeaturizer\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6361b9-f78a-4aa1-a9cd-8352dbc58d3f",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d21fdd-7669-42f7-8a23-9db65da43f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set true actives\n",
    "plec_train_true_actives = pd.read_csv('Path_to_csv')\n",
    "grid_train_true_actives = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "# test sets true actives\n",
    "plec_test_true_actives = pd.read_csv('Path_to_csv')\n",
    "grid_test_true_actives = pd.read_csv('Path_to_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6714d-bd99-43b3-a4c8-6132f6960df4",
   "metadata": {},
   "source": [
    "# **Load Decoys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d95a3-63e4-47f4-9882-c75196e26d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set random_decoys\n",
    "plec_train_random_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_train_random_decoys = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "# test sets random_decoys\n",
    "plec_test_random_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_test_random_decoys = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "\n",
    "# training set deepcoy decoys\n",
    "plec_train_deepcoy_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_train_deepcoy_decoys = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "# test sets deepcoy decoys\n",
    "plec_test_deepcoy_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_test_deepcoy_decoys = pd.read_csv('Path_to_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d13e15-a27a-40ef-9924-759e2cc2cbbb",
   "metadata": {},
   "source": [
    "# **Cross validation with DeepCoys in the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a246e485-62f6-4340-87dc-235b3e5dc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_train = pd.concat([plec_train_true_actives,plec_train_random_decoys])\n",
    "grid_train = pd.concat([grid_train_true_actives,grid_train_random_decoys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "354b8c9d-168e-4a81-9dec-402189725e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X_plec_train, y_plec_train = plec_train.drop(['class', 'potency','index'], axis= 1), plec_train['potency']\n",
    "X_grid_train, y_grid_train = grid_train.drop(['class', 'potency'], axis= 1), grid_train['potency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2296fdbf-61e9-4a91-8804-3f226941385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_train_reset = plec_train.reset_index(drop=True)\n",
    "grid_train_reset = grid_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e90b61d7-b83d-4cc5-8937-2b7851fe2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plec_train, y_plec_train = plec_train_reset.drop(['class', 'potency','index'], axis= 1), plec_train_reset['potency']\n",
    "X_grid_train, y_grid_train = grid_train_reset.drop(['class', 'potency'], axis= 1), grid_train_reset['potency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aead204f-997f-4b7d-8bf5-9c67e197b2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest...\n",
      "Fold 1 - Threshold: 2.1171, F1: 0.8057, AVG-Pre: 0.8430, ROC-AUC: 0.9772, PR-AUC: 0.8426, Precision: 0.8586, Recall: 0.7589, MAE: 0.1061, MCC: 0.8027\n",
      "Fold 2 - Threshold: 2.1004, F1: 0.7845, AVG-Pre: 0.8725, ROC-AUC: 0.9910, PR-AUC: 0.8722, Precision: 0.7712, Recall: 0.7982, MAE: 0.1055, MCC: 0.7790\n",
      "Fold 3 - Threshold: 2.1575, F1: 0.8087, AVG-Pre: 0.8854, ROC-AUC: 0.9923, PR-AUC: 0.8851, Precision: 0.9610, Recall: 0.6981, MAE: 0.1083, MCC: 0.8156\n",
      "Fold 4 - Threshold: 2.1219, F1: 0.8148, AVG-Pre: 0.8613, ROC-AUC: 0.9794, PR-AUC: 0.8609, Precision: 0.8750, Recall: 0.7624, MAE: 0.1074, MCC: 0.8129\n",
      "Fold 5 - Threshold: 2.1314, F1: 0.8660, AVG-Pre: 0.9043, ROC-AUC: 0.9797, PR-AUC: 0.9042, Precision: 0.9545, Recall: 0.7925, MAE: 0.1042, MCC: 0.8670\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Threshold: 2.1257 (±0.0188)\n",
      "Mean F1: 0.8159 (±0.0270)\n",
      "Mean AVG_Pre: 0.8733 (±0.0208)\n",
      "Mean ROC-AUC: 0.9839 (±0.0064)\n",
      "Mean PR-AUC: 0.8730 (±0.0209)\n",
      "Mean Precision: 0.8841 (±0.0698)\n",
      "Mean Recall: 0.7620 (±0.0356)\n",
      "Mean MCC: 0.8154 (±0.0288)\n",
      "Mean MAE: 0.1063 (±0.0014)\n",
      "\n",
      "Evaluating XGBoost...\n",
      "Fold 1 - Threshold: 2.0296, F1: 0.8899, AVG-Pre: 0.9249, ROC-AUC: 0.9912, PR-AUC: 0.9246, Precision: 0.9151, Recall: 0.8661, MAE: 0.3530, MCC: 0.8876\n",
      "Fold 2 - Threshold: 2.2016, F1: 0.8807, AVG-Pre: 0.9381, ROC-AUC: 0.9914, PR-AUC: 0.9380, Precision: 0.9231, Recall: 0.8421, MAE: 0.3547, MCC: 0.8788\n",
      "Fold 3 - Threshold: 2.2582, F1: 0.9275, AVG-Pre: 0.9436, ROC-AUC: 0.9944, PR-AUC: 0.9432, Precision: 0.9505, Recall: 0.9057, MAE: 0.3534, MCC: 0.9261\n",
      "Fold 4 - Threshold: 2.6168, F1: 0.8962, AVG-Pre: 0.9330, ROC-AUC: 0.9948, PR-AUC: 0.9328, Precision: 1.0000, Recall: 0.8119, MAE: 0.3523, MCC: 0.8991\n",
      "Fold 5 - Threshold: 2.5144, F1: 0.9082, AVG-Pre: 0.9172, ROC-AUC: 0.9811, PR-AUC: 0.9172, Precision: 0.9889, Recall: 0.8396, MAE: 0.3492, MCC: 0.9093\n",
      "\n",
      "XGBoost Results:\n",
      "Mean Threshold: 2.3241 (±0.2135)\n",
      "Mean F1: 0.9005 (±0.0162)\n",
      "Mean AVG_Pre: 0.9314 (±0.0094)\n",
      "Mean ROC-AUC: 0.9906 (±0.0049)\n",
      "Mean PR-AUC: 0.9311 (±0.0093)\n",
      "Mean Precision: 0.9555 (±0.0341)\n",
      "Mean Recall: 0.8531 (±0.0314)\n",
      "Mean MCC: 0.9002 (±0.0166)\n",
      "Mean MAE: 0.3525 (±0.0018)\n",
      "\n",
      "Evaluating ANN...\n",
      "Fold 1 - Threshold: 3.2478, F1: 0.6927, AVG-Pre: 0.6829, ROC-AUC: 0.9217, PR-AUC: 0.6825, Precision: 0.9254, Recall: 0.5536, MAE: 0.3236, MCC: 0.7107\n",
      "Fold 2 - Threshold: 3.2593, F1: 0.6932, AVG-Pre: 0.6734, ROC-AUC: 0.9376, PR-AUC: 0.6730, Precision: 0.9839, Recall: 0.5351, MAE: 0.3101, MCC: 0.7210\n",
      "Fold 3 - Threshold: 3.3475, F1: 0.7222, AVG-Pre: 0.7004, ROC-AUC: 0.9317, PR-AUC: 0.7000, Precision: 0.8784, Recall: 0.6132, MAE: 0.3271, MCC: 0.7289\n",
      "Fold 4 - Threshold: 3.3462, F1: 0.6500, AVG-Pre: 0.6265, ROC-AUC: 0.9226, PR-AUC: 0.6259, Precision: 0.8814, Recall: 0.5149, MAE: 0.3285, MCC: 0.6684\n",
      "Fold 5 - Threshold: 3.4472, F1: 0.7059, AVG-Pre: 0.7078, ROC-AUC: 0.9237, PR-AUC: 0.7073, Precision: 0.9375, Recall: 0.5660, MAE: 0.3328, MCC: 0.7239\n",
      "\n",
      "ANN Results:\n",
      "Mean Threshold: 3.3296 (±0.0722)\n",
      "Mean F1: 0.6928 (±0.0240)\n",
      "Mean AVG_Pre: 0.6782 (±0.0286)\n",
      "Mean ROC-AUC: 0.9275 (±0.0062)\n",
      "Mean PR-AUC: 0.6777 (±0.0286)\n",
      "Mean Precision: 0.9213 (±0.0391)\n",
      "Mean Recall: 0.5566 (±0.0332)\n",
      "Mean MCC: 0.7106 (±0.0219)\n",
      "Mean MAE: 0.3244 (±0.0077)\n",
      "\n",
      "Overall Results:\n",
      "Random Forest:\n",
      "  Mean Threshold: 2.1257 (±0.0188)\n",
      "  Mean F1: 0.8159 (±0.0270)\n",
      "  Mean AVG_Pre: 0.8733 (±0.0208)\n",
      "  Mean ROC-AUC: 0.9839 (±0.0064)\n",
      "  Mean PR-AUC: 0.8730 (±0.0209)\n",
      "  Mean Precision: 0.8841 (±0.0698)\n",
      "  Mean Recall: 0.7620 (±0.0356)\n",
      "  Mean MCC: 0.8154 (±0.0288)\n",
      "  Mean MAE: 0.1063 (±0.0014)\n",
      "\n",
      "XGBoost:\n",
      "  Mean Threshold: 2.3241 (±0.2135)\n",
      "  Mean F1: 0.9005 (±0.0162)\n",
      "  Mean AVG_Pre: 0.9314 (±0.0094)\n",
      "  Mean ROC-AUC: 0.9906 (±0.0049)\n",
      "  Mean PR-AUC: 0.9311 (±0.0093)\n",
      "  Mean Precision: 0.9555 (±0.0341)\n",
      "  Mean Recall: 0.8531 (±0.0314)\n",
      "  Mean MCC: 0.9002 (±0.0166)\n",
      "  Mean MAE: 0.3525 (±0.0018)\n",
      "\n",
      "ANN:\n",
      "  Mean Threshold: 3.3296 (±0.0722)\n",
      "  Mean F1: 0.6928 (±0.0240)\n",
      "  Mean AVG_Pre: 0.6782 (±0.0286)\n",
      "  Mean ROC-AUC: 0.9275 (±0.0062)\n",
      "  Mean PR-AUC: 0.6777 (±0.0286)\n",
      "  Mean Precision: 0.9213 (±0.0391)\n",
      "  Mean Recall: 0.5566 (±0.0332)\n",
      "  Mean MCC: 0.7106 (±0.0219)\n",
      "  Mean MAE: 0.3244 (±0.0077)\n",
      "\n",
      "Mean Scores for Each Model (rounded to three decimal places):\n",
      "Threshold: [2.126, 2.324, 3.33]\n",
      "F1: [0.816, 0.901, 0.693]\n",
      "AVG-Prec: [0.873, 0.931, 0.678]\n",
      "ROC-AUC: [0.984, 0.991, 0.927]\n",
      "PR-AUC: [0.873, 0.931, 0.678]\n",
      "Precision: [0.884, 0.956, 0.921]\n",
      "Recall: [0.762, 0.853, 0.557]\n",
      "MCC: [0.815, 0.9, 0.711]\n",
      "MAE: [0.106, 0.352, 0.324]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, matthews_corrcoef, mean_absolute_error, precision_recall_curve, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    return optimal_threshold\n",
    "\n",
    "def convert_to_binary_test(y, threshold=2):\n",
    "    return (y > threshold).astype(int)\n",
    "    \n",
    "def convert_to_binary(y, threshold):\n",
    "    return (y > threshold).astype(int)\n",
    "\n",
    "# Initialize the KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the models in a dictionary\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=8, n_estimators=270, n_jobs=40),\n",
    "    'XGBoost': XGBRegressor(learning_rate=0.01, max_depth=7, colsample_bytree=0.73, gamma=1.96, min_child_weight=8.0, subsample=0.71, n_estimators=150),\n",
    "    'ANN': MLPRegressor(hidden_layer_sizes=50, activation='tanh', alpha=0.0070, learning_rate='invscaling', solver='sgd')\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation for each model\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    mae_scores, roc_auc_scores, pr_auc_scores, precision_scores, recall_scores, mcc_scores, avg_precision_scores, f1_scores, thresholds = [], [], [], [], [], [], [], [], []\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X_plec_train):\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_test = X_plec_train.iloc[train_index], X_plec_train.iloc[test_index]\n",
    "        y_train, y_test = y_plec_train.iloc[train_index], y_plec_train.iloc[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate regression metric (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Convert continuous true values to binary\n",
    "        #y_pred_binary = convert_to_binary(y_pred)\n",
    "        y_test_binary = convert_to_binary_test(y_test)        \n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_optimal_threshold(y_test_binary, y_pred)\n",
    "        thresholds.append(optimal_threshold)\n",
    "        \n",
    "        # Convert continuous predictions and true values to binary using optimal threshold\n",
    "        y_pred_binary = convert_to_binary(y_pred, optimal_threshold)\n",
    "        #y_test_binary = convert_to_binary(y_test, optimal_threshold)\n",
    "        \n",
    "        # Calculate classification metrics\n",
    "        roc_auc = roc_auc_score(y_test_binary, y_pred)\n",
    "        avg_precision = average_precision_score(y_test_binary, y_pred)\n",
    "        precision = precision_score(y_test_binary, y_pred_binary)\n",
    "        recall = recall_score(y_test_binary, y_pred_binary)\n",
    "        mcc = matthews_corrcoef(y_test_binary, y_pred_binary)\n",
    "        f1 = f1_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "        # Calculate PR-AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_test_binary, y_pred)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "        \n",
    "        # Append scores\n",
    "        mae_scores.append(mae)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        pr_auc_scores.append(pr_auc)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        mcc_scores.append(mcc)\n",
    "        avg_precision_scores.append(avg_precision)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold {fold} - Threshold: {optimal_threshold:.4f}, F1: {f1:.4f}, AVG-Pre: {avg_precision:.4f}, ROC-AUC: {roc_auc:.4f}, PR-AUC: {pr_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, MAE: {mae:.4f}, MCC: {mcc:.4f}\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate mean and standard deviation of scores\n",
    "    mean_threshold, std_threshold = np.mean(thresholds), np.std(thresholds)\n",
    "    mean_f1, std_f1 = np.mean(f1_scores), np.std(f1_scores)\n",
    "    mean_avg_pre, std_avg_pre = np.mean(avg_precision_scores), np.std(avg_precision_scores)\n",
    "    mean_roc_auc, std_roc_auc = np.mean(roc_auc_scores), np.std(roc_auc_scores)\n",
    "    mean_pr_auc, std_pr_auc = np.mean(pr_auc_scores), np.std(pr_auc_scores)\n",
    "    mean_precision, std_precision = np.mean(precision_scores), np.std(precision_scores)\n",
    "    mean_recall, std_recall = np.mean(recall_scores), np.std(recall_scores)\n",
    "    mean_mcc, std_mcc = np.mean(mcc_scores), np.std(mcc_scores)\n",
    "    mean_mae, std_mae = np.mean(mae_scores), np.std(mae_scores)\n",
    "    \n",
    "    results[model_name] = (mean_threshold, std_threshold,\n",
    "                           mean_f1, std_f1,\n",
    "                           mean_avg_pre, std_avg_pre, \n",
    "                           mean_roc_auc, std_roc_auc,\n",
    "                           mean_pr_auc, std_pr_auc,\n",
    "                           mean_precision, std_precision, \n",
    "                           mean_recall, std_recall,\n",
    "                           mean_mcc, std_mcc,\n",
    "                           mean_mae, std_mae)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Mean Threshold: {mean_threshold:.4f} (±{std_threshold:.4f})\")\n",
    "    print(f\"Mean F1: {mean_f1:.4f} (±{std_f1:.4f})\")\n",
    "    print(f\"Mean AVG_Pre: {mean_avg_pre:.4f} (±{std_avg_pre:.4f})\")\n",
    "    print(f\"Mean ROC-AUC: {mean_roc_auc:.4f} (±{std_roc_auc:.4f})\")\n",
    "    print(f\"Mean PR-AUC: {mean_pr_auc:.4f} (±{std_pr_auc:.4f})\")\n",
    "    print(f\"Mean Precision: {mean_precision:.4f} (±{std_precision:.4f})\")\n",
    "    print(f\"Mean Recall: {mean_recall:.4f} (±{std_recall:.4f})\")\n",
    "    print(f\"Mean MCC: {mean_mcc:.4f} (±{std_mcc:.4f})\")\n",
    "    print(f\"Mean MAE: {mean_mae:.4f} (±{std_mae:.4f})\\n\")\n",
    "\n",
    "# Print overall results\n",
    "print(\"Overall Results:\")\n",
    "for model_name, scores in results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Mean Threshold: {scores[0]:.4f} (±{scores[1]:.4f})\")\n",
    "    print(f\"  Mean F1: {scores[2]:.4f} (±{scores[3]:.4f})\")\n",
    "    print(f\"  Mean AVG_Pre: {scores[4]:.4f} (±{scores[5]:.4f})\")\n",
    "    print(f\"  Mean ROC-AUC: {scores[6]:.4f} (±{scores[7]:.4f})\")\n",
    "    print(f\"  Mean PR-AUC: {scores[8]:.4f} (±{scores[9]:.4f})\")\n",
    "    print(f\"  Mean Precision: {scores[10]:.4f} (±{scores[11]:.4f})\")\n",
    "    print(f\"  Mean Recall: {scores[12]:.4f} (±{scores[13]:.4f})\")\n",
    "    print(f\"  Mean MCC: {scores[14]:.4f} (±{scores[15]:.4f})\")\n",
    "    print(f\"  Mean MAE: {scores[16]:.4f} (±{scores[17]:.4f})\")\n",
    "    print()\n",
    "\n",
    "# Collect mean scores for each model\n",
    "mean_scores = {metric: [] for metric in ['Threshold', 'F1', 'AVG-Prec', 'ROC-AUC', 'PR-AUC', 'Precision', 'Recall', 'MCC', 'MAE']}\n",
    "\n",
    "for model_name, scores in results.items():\n",
    "    mean_scores['Threshold'].append(round(scores[0], 3))\n",
    "    mean_scores['F1'].append(round(scores[2], 3))\n",
    "    mean_scores['AVG-Prec'].append(round(scores[4], 3))\n",
    "    mean_scores['ROC-AUC'].append(round(scores[6], 3))\n",
    "    mean_scores['PR-AUC'].append(round(scores[8], 3))\n",
    "    mean_scores['Precision'].append(round(scores[10], 3))\n",
    "    mean_scores['Recall'].append(round(scores[12], 3))\n",
    "    mean_scores['MCC'].append(round(scores[14], 3))\n",
    "    mean_scores['MAE'].append(round(scores[16], 3))\n",
    "\n",
    "print(\"Mean Scores for Each Model (rounded to three decimal places):\")\n",
    "for metric, scores in mean_scores.items():\n",
    "    print(f\"{metric}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35e057ad-c6b9-46fb-863a-f72f3d229dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest...\n",
      "Fold 1 - Threshold: 2.1643, F1: 0.7293, AVG-Pre: 0.7321, ROC-AUC: 0.9288, PR-AUC: 0.7317, Precision: 0.9565, Recall: 0.5893, MAE: 0.1194, MCC: 0.7463\n",
      "Fold 2 - Threshold: 2.1454, F1: 0.7292, AVG-Pre: 0.7666, ROC-AUC: 0.9615, PR-AUC: 0.7662, Precision: 0.8974, Recall: 0.6140, MAE: 0.1223, MCC: 0.7372\n",
      "Fold 3 - Threshold: 2.1568, F1: 0.7735, AVG-Pre: 0.7833, ROC-AUC: 0.9658, PR-AUC: 0.7830, Precision: 0.9333, Recall: 0.6604, MAE: 0.1225, MCC: 0.7810\n",
      "Fold 4 - Threshold: 2.1528, F1: 0.6864, AVG-Pre: 0.7403, ROC-AUC: 0.9516, PR-AUC: 0.7398, Precision: 0.8529, Recall: 0.5743, MAE: 0.1173, MCC: 0.6945\n",
      "Fold 5 - Threshold: 2.1381, F1: 0.7919, AVG-Pre: 0.8308, ROC-AUC: 0.9717, PR-AUC: 0.8305, Precision: 0.8571, Recall: 0.7358, MAE: 0.1180, MCC: 0.7897\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Threshold: 2.1515 (±0.0091)\n",
      "Mean F1: 0.7420 (±0.0371)\n",
      "Mean AVG_Pre: 0.7706 (±0.0352)\n",
      "Mean ROC-AUC: 0.9559 (±0.0150)\n",
      "Mean PR-AUC: 0.7703 (±0.0353)\n",
      "Mean Precision: 0.8995 (±0.0409)\n",
      "Mean Recall: 0.6348 (±0.0584)\n",
      "Mean MCC: 0.7497 (±0.0340)\n",
      "Mean MAE: 0.1199 (±0.0022)\n",
      "\n",
      "Evaluating XGBoost...\n",
      "Fold 1 - Threshold: 2.3229, F1: 0.9159, AVG-Pre: 0.9228, ROC-AUC: 0.9673, PR-AUC: 0.9231, Precision: 0.9608, Recall: 0.8750, MAE: 0.3539, MCC: 0.9149\n",
      "Fold 2 - Threshold: 2.2726, F1: 0.9189, AVG-Pre: 0.9256, ROC-AUC: 0.9908, PR-AUC: 0.9255, Precision: 0.9444, Recall: 0.8947, MAE: 0.3532, MCC: 0.9172\n",
      "Fold 3 - Threshold: 2.2601, F1: 0.9469, AVG-Pre: 0.9704, ROC-AUC: 0.9911, PR-AUC: 0.9705, Precision: 0.9703, Recall: 0.9245, MAE: 0.3538, MCC: 0.9459\n",
      "Fold 4 - Threshold: 2.3636, F1: 0.9184, AVG-Pre: 0.9331, ROC-AUC: 0.9810, PR-AUC: 0.9331, Precision: 0.9474, Recall: 0.8911, MAE: 0.3522, MCC: 0.9170\n",
      "Fold 5 - Threshold: 2.3975, F1: 0.9366, AVG-Pre: 0.9406, ROC-AUC: 0.9913, PR-AUC: 0.9404, Precision: 0.9697, Recall: 0.9057, MAE: 0.3499, MCC: 0.9357\n",
      "\n",
      "XGBoost Results:\n",
      "Mean Threshold: 2.3233 (±0.0523)\n",
      "Mean F1: 0.9273 (±0.0122)\n",
      "Mean AVG_Pre: 0.9385 (±0.0171)\n",
      "Mean ROC-AUC: 0.9843 (±0.0094)\n",
      "Mean PR-AUC: 0.9385 (±0.0171)\n",
      "Mean Precision: 0.9585 (±0.0109)\n",
      "Mean Recall: 0.8982 (±0.0164)\n",
      "Mean MCC: 0.9262 (±0.0124)\n",
      "Mean MAE: 0.3526 (±0.0015)\n",
      "\n",
      "Evaluating ANN...\n",
      "Fold 1 - Threshold: 2.9661, F1: 0.6163, AVG-Pre: 0.5686, ROC-AUC: 0.8687, PR-AUC: 0.5682, Precision: 0.8833, Recall: 0.4732, MAE: 0.2660, MCC: 0.6406\n",
      "Fold 2 - Threshold: 2.8433, F1: 0.6404, AVG-Pre: 0.5796, ROC-AUC: 0.8282, PR-AUC: 0.5793, Precision: 0.8906, Recall: 0.5000, MAE: 0.2217, MCC: 0.6615\n",
      "Fold 3 - Threshold: 2.8384, F1: 0.6552, AVG-Pre: 0.6361, ROC-AUC: 0.9055, PR-AUC: 0.6357, Precision: 0.8382, Recall: 0.5377, MAE: 0.2563, MCC: 0.6654\n",
      "Fold 4 - Threshold: 2.8175, F1: 0.5161, AVG-Pre: 0.4636, ROC-AUC: 0.8388, PR-AUC: 0.4629, Precision: 0.7407, Recall: 0.3960, MAE: 0.2630, MCC: 0.5345\n",
      "Fold 5 - Threshold: 2.8413, F1: 0.6746, AVG-Pre: 0.6136, ROC-AUC: 0.8690, PR-AUC: 0.6132, Precision: 0.9048, Recall: 0.5377, MAE: 0.2458, MCC: 0.6924\n",
      "\n",
      "ANN Results:\n",
      "Mean Threshold: 2.8613 (±0.0532)\n",
      "Mean F1: 0.6205 (±0.0556)\n",
      "Mean AVG_Pre: 0.5723 (±0.0594)\n",
      "Mean ROC-AUC: 0.8620 (±0.0271)\n",
      "Mean PR-AUC: 0.5718 (±0.0595)\n",
      "Mean Precision: 0.8515 (±0.0597)\n",
      "Mean Recall: 0.4889 (±0.0525)\n",
      "Mean MCC: 0.6389 (±0.0547)\n",
      "Mean MAE: 0.2505 (±0.0160)\n",
      "\n",
      "Overall Results:\n",
      "Random Forest:\n",
      "  Mean Threshold: 2.1515 (±0.0091)\n",
      "  Mean F1: 0.7420 (±0.0371)\n",
      "  Mean AVG_Pre: 0.7706 (±0.0352)\n",
      "  Mean ROC-AUC: 0.9559 (±0.0150)\n",
      "  Mean PR-AUC: 0.7703 (±0.0353)\n",
      "  Mean Precision: 0.8995 (±0.0409)\n",
      "  Mean Recall: 0.6348 (±0.0584)\n",
      "  Mean MCC: 0.7497 (±0.0340)\n",
      "  Mean MAE: 0.1199 (±0.0022)\n",
      "\n",
      "XGBoost:\n",
      "  Mean Threshold: 2.3233 (±0.0523)\n",
      "  Mean F1: 0.9273 (±0.0122)\n",
      "  Mean AVG_Pre: 0.9385 (±0.0171)\n",
      "  Mean ROC-AUC: 0.9843 (±0.0094)\n",
      "  Mean PR-AUC: 0.9385 (±0.0171)\n",
      "  Mean Precision: 0.9585 (±0.0109)\n",
      "  Mean Recall: 0.8982 (±0.0164)\n",
      "  Mean MCC: 0.9262 (±0.0124)\n",
      "  Mean MAE: 0.3526 (±0.0015)\n",
      "\n",
      "ANN:\n",
      "  Mean Threshold: 2.8613 (±0.0532)\n",
      "  Mean F1: 0.6205 (±0.0556)\n",
      "  Mean AVG_Pre: 0.5723 (±0.0594)\n",
      "  Mean ROC-AUC: 0.8620 (±0.0271)\n",
      "  Mean PR-AUC: 0.5718 (±0.0595)\n",
      "  Mean Precision: 0.8515 (±0.0597)\n",
      "  Mean Recall: 0.4889 (±0.0525)\n",
      "  Mean MCC: 0.6389 (±0.0547)\n",
      "  Mean MAE: 0.2505 (±0.0160)\n",
      "\n",
      "Mean Scores for Each Model (rounded to three decimal places):\n",
      "Threshold: [2.151, 2.323, 2.861]\n",
      "F1: [0.742, 0.927, 0.621]\n",
      "AVG-Prec: [0.771, 0.939, 0.572]\n",
      "ROC-AUC: [0.956, 0.984, 0.862]\n",
      "PR-AUC: [0.77, 0.939, 0.572]\n",
      "Precision: [0.899, 0.959, 0.852]\n",
      "Recall: [0.635, 0.898, 0.489]\n",
      "MCC: [0.75, 0.926, 0.639]\n",
      "MAE: [0.12, 0.353, 0.251]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, matthews_corrcoef, mean_absolute_error, precision_recall_curve, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    return optimal_threshold\n",
    "\n",
    "def convert_to_binary_test(y, threshold=2):\n",
    "    return (y > threshold).astype(int)\n",
    "    \n",
    "def convert_to_binary(y, threshold):\n",
    "    return (y > threshold).astype(int)\n",
    "\n",
    "# Initialize the KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the models in a dictionary\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=8, n_estimators=270, n_jobs=40),\n",
    "    'XGBoost': XGBRegressor(learning_rate=0.01, max_depth=7, colsample_bytree=0.73, gamma=1.96, min_child_weight=8.0, subsample=0.71, n_estimators=150),\n",
    "    'ANN': MLPRegressor(hidden_layer_sizes=50, activation='tanh', alpha=0.0070, learning_rate='invscaling', solver='sgd')\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation for each model\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    mae_scores, roc_auc_scores, pr_auc_scores, precision_scores, recall_scores, mcc_scores, avg_precision_scores, f1_scores, thresholds = [], [], [], [], [], [], [], [], []\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X_grid_train):\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_test = X_grid_train.iloc[train_index], X_grid_train.iloc[test_index]\n",
    "        y_train, y_test = y_grid_train.iloc[train_index], y_grid_train.iloc[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate regression metric (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Convert continuous true values to binary\n",
    "        #y_pred_binary = convert_to_binary(y_pred)\n",
    "        y_test_binary = convert_to_binary_test(y_test)        \n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_optimal_threshold(y_test_binary, y_pred)\n",
    "        thresholds.append(optimal_threshold)\n",
    "        \n",
    "        # Convert continuous predictions and true values to binary using optimal threshold\n",
    "        y_pred_binary = convert_to_binary(y_pred, optimal_threshold)\n",
    "        #y_test_binary = convert_to_binary(y_test, optimal_threshold)\n",
    "        \n",
    "        # Calculate classification metrics\n",
    "        roc_auc = roc_auc_score(y_test_binary, y_pred)\n",
    "        avg_precision = average_precision_score(y_test_binary, y_pred)\n",
    "        precision = precision_score(y_test_binary, y_pred_binary)\n",
    "        recall = recall_score(y_test_binary, y_pred_binary)\n",
    "        mcc = matthews_corrcoef(y_test_binary, y_pred_binary)\n",
    "        f1 = f1_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "        # Calculate PR-AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_test_binary, y_pred)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "        \n",
    "        # Append scores\n",
    "        mae_scores.append(mae)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        pr_auc_scores.append(pr_auc)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        mcc_scores.append(mcc)\n",
    "        avg_precision_scores.append(avg_precision)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold {fold} - Threshold: {optimal_threshold:.4f}, F1: {f1:.4f}, AVG-Pre: {avg_precision:.4f}, ROC-AUC: {roc_auc:.4f}, PR-AUC: {pr_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, MAE: {mae:.4f}, MCC: {mcc:.4f}\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate mean and standard deviation of scores\n",
    "    mean_threshold, std_threshold = np.mean(thresholds), np.std(thresholds)\n",
    "    mean_f1, std_f1 = np.mean(f1_scores), np.std(f1_scores)\n",
    "    mean_avg_pre, std_avg_pre = np.mean(avg_precision_scores), np.std(avg_precision_scores)\n",
    "    mean_roc_auc, std_roc_auc = np.mean(roc_auc_scores), np.std(roc_auc_scores)\n",
    "    mean_pr_auc, std_pr_auc = np.mean(pr_auc_scores), np.std(pr_auc_scores)\n",
    "    mean_precision, std_precision = np.mean(precision_scores), np.std(precision_scores)\n",
    "    mean_recall, std_recall = np.mean(recall_scores), np.std(recall_scores)\n",
    "    mean_mcc, std_mcc = np.mean(mcc_scores), np.std(mcc_scores)\n",
    "    mean_mae, std_mae = np.mean(mae_scores), np.std(mae_scores)\n",
    "    \n",
    "    results[model_name] = (mean_threshold, std_threshold,\n",
    "                           mean_f1, std_f1,\n",
    "                           mean_avg_pre, std_avg_pre, \n",
    "                           mean_roc_auc, std_roc_auc,\n",
    "                           mean_pr_auc, std_pr_auc,\n",
    "                           mean_precision, std_precision, \n",
    "                           mean_recall, std_recall,\n",
    "                           mean_mcc, std_mcc,\n",
    "                           mean_mae, std_mae)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Mean Threshold: {mean_threshold:.4f} (±{std_threshold:.4f})\")\n",
    "    print(f\"Mean F1: {mean_f1:.4f} (±{std_f1:.4f})\")\n",
    "    print(f\"Mean AVG_Pre: {mean_avg_pre:.4f} (±{std_avg_pre:.4f})\")\n",
    "    print(f\"Mean ROC-AUC: {mean_roc_auc:.4f} (±{std_roc_auc:.4f})\")\n",
    "    print(f\"Mean PR-AUC: {mean_pr_auc:.4f} (±{std_pr_auc:.4f})\")\n",
    "    print(f\"Mean Precision: {mean_precision:.4f} (±{std_precision:.4f})\")\n",
    "    print(f\"Mean Recall: {mean_recall:.4f} (±{std_recall:.4f})\")\n",
    "    print(f\"Mean MCC: {mean_mcc:.4f} (±{std_mcc:.4f})\")\n",
    "    print(f\"Mean MAE: {mean_mae:.4f} (±{std_mae:.4f})\\n\")\n",
    "\n",
    "# Print overall results\n",
    "print(\"Overall Results:\")\n",
    "for model_name, scores in results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Mean Threshold: {scores[0]:.4f} (±{scores[1]:.4f})\")\n",
    "    print(f\"  Mean F1: {scores[2]:.4f} (±{scores[3]:.4f})\")\n",
    "    print(f\"  Mean AVG_Pre: {scores[4]:.4f} (±{scores[5]:.4f})\")\n",
    "    print(f\"  Mean ROC-AUC: {scores[6]:.4f} (±{scores[7]:.4f})\")\n",
    "    print(f\"  Mean PR-AUC: {scores[8]:.4f} (±{scores[9]:.4f})\")\n",
    "    print(f\"  Mean Precision: {scores[10]:.4f} (±{scores[11]:.4f})\")\n",
    "    print(f\"  Mean Recall: {scores[12]:.4f} (±{scores[13]:.4f})\")\n",
    "    print(f\"  Mean MCC: {scores[14]:.4f} (±{scores[15]:.4f})\")\n",
    "    print(f\"  Mean MAE: {scores[16]:.4f} (±{scores[17]:.4f})\")\n",
    "    print()\n",
    "\n",
    "# Collect mean scores for each model\n",
    "mean_scores = {metric: [] for metric in ['Threshold', 'F1', 'AVG-Prec', 'ROC-AUC', 'PR-AUC', 'Precision', 'Recall', 'MCC', 'MAE']}\n",
    "\n",
    "for model_name, scores in results.items():\n",
    "    mean_scores['Threshold'].append(round(scores[0], 3))\n",
    "    mean_scores['F1'].append(round(scores[2], 3))\n",
    "    mean_scores['AVG-Prec'].append(round(scores[4], 3))\n",
    "    mean_scores['ROC-AUC'].append(round(scores[6], 3))\n",
    "    mean_scores['PR-AUC'].append(round(scores[8], 3))\n",
    "    mean_scores['Precision'].append(round(scores[10], 3))\n",
    "    mean_scores['Recall'].append(round(scores[12], 3))\n",
    "    mean_scores['MCC'].append(round(scores[14], 3))\n",
    "    mean_scores['MAE'].append(round(scores[16], 3))\n",
    "\n",
    "print(\"Mean Scores for Each Model (rounded to three decimal places):\")\n",
    "for metric, scores in mean_scores.items():\n",
    "    print(f\"{metric}: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ab555-43c0-462a-88ad-7fb8f03db6ef",
   "metadata": {},
   "source": [
    "# **Cross validation with Random decoys in the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21708b-6dca-499d-8c79-4e9656dad066",
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_train = pd.concat([plec_train_true_actives,plec_train_deepcoys_decoys])\n",
    "grid_train = pd.concat([grid_train_true_actives,grid_train_deepcoys_decoys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa5561fa-af4f-49aa-a140-39f4646d7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X_plec_train, y_plec_train = plec_train.drop(['class', 'potency','index'], axis= 1), plec_train['potency']\n",
    "X_grid_train, y_grid_train = grid_train.drop(['class', 'potency','index'], axis= 1), grid_train['potency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a36474d-26a0-42e6-812b-f386ff03e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_train_reset = plec_train.reset_index(drop=True)\n",
    "grid_train_reset = grid_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "86c15abd-33d0-4d5e-8941-16dc64ee7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plec_train, y_plec_train = plec_train_reset.drop(['class', 'potency','index'], axis= 1), plec_train_reset['potency']\n",
    "X_grid_train, y_grid_train = grid_train_reset.drop(['class', 'potency','index'], axis= 1), grid_train_reset['potency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7453c16-b96a-42ec-bc2b-432b472c0e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest...\n",
      "Fold 1 - Threshold: 2.1701, F1: 0.8700, AVG-Pre: 0.9276, ROC-AUC: 0.9969, PR-AUC: 0.9273, Precision: 0.8739, Recall: 0.8661, MAE: 0.0999, MCC: 0.8667\n",
      "Fold 2 - Threshold: 2.1399, F1: 0.8306, AVG-Pre: 0.8963, ROC-AUC: 0.9969, PR-AUC: 0.8959, Precision: 0.7687, Recall: 0.9035, MAE: 0.1003, MCC: 0.8288\n",
      "Fold 3 - Threshold: 2.2105, F1: 0.9005, AVG-Pre: 0.9578, ROC-AUC: 0.9987, PR-AUC: 0.9576, Precision: 0.9048, Recall: 0.8962, MAE: 0.1010, MCC: 0.8981\n",
      "Fold 4 - Threshold: 2.2156, F1: 0.8235, AVG-Pre: 0.9043, ROC-AUC: 0.9957, PR-AUC: 0.9039, Precision: 0.8953, Recall: 0.7624, MAE: 0.0995, MCC: 0.8226\n",
      "Fold 5 - Threshold: 2.1341, F1: 0.8571, AVG-Pre: 0.9373, ROC-AUC: 0.9976, PR-AUC: 0.9371, Precision: 0.7920, Recall: 0.9340, MAE: 0.0961, MCC: 0.8565\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Threshold: 2.1740 (±0.0341)\n",
      "Mean F1: 0.8563 (±0.0278)\n",
      "Mean AVG_Pre: 0.9247 (±0.0223)\n",
      "Mean ROC-AUC: 0.9972 (±0.0010)\n",
      "Mean PR-AUC: 0.9243 (±0.0224)\n",
      "Mean Precision: 0.8469 (±0.0558)\n",
      "Mean Recall: 0.8724 (±0.0591)\n",
      "Mean MCC: 0.8545 (±0.0273)\n",
      "Mean MAE: 0.0994 (±0.0017)\n",
      "\n",
      "Evaluating XGBoost...\n",
      "Fold 1 - Threshold: 2.0718, F1: 0.9593, AVG-Pre: 0.9875, ROC-AUC: 0.9996, PR-AUC: 0.9875, Precision: 0.9725, Recall: 0.9464, MAE: 0.3493, MCC: 0.9584\n",
      "Fold 2 - Threshold: 2.1087, F1: 0.9279, AVG-Pre: 0.9519, ROC-AUC: 0.9960, PR-AUC: 0.9518, Precision: 0.9537, Recall: 0.9035, MAE: 0.3542, MCC: 0.9265\n",
      "Fold 3 - Threshold: 2.0068, F1: 0.9717, AVG-Pre: 0.9916, ROC-AUC: 0.9997, PR-AUC: 0.9915, Precision: 0.9717, Recall: 0.9717, MAE: 0.3549, MCC: 0.9710\n",
      "Fold 4 - Threshold: 2.6520, F1: 0.9490, AVG-Pre: 0.9793, ROC-AUC: 0.9991, PR-AUC: 0.9792, Precision: 0.9789, Recall: 0.9208, MAE: 0.3527, MCC: 0.9483\n",
      "Fold 5 - Threshold: 2.2147, F1: 0.9353, AVG-Pre: 0.9758, ROC-AUC: 0.9991, PR-AUC: 0.9757, Precision: 0.9895, Recall: 0.8868, MAE: 0.3524, MCC: 0.9353\n",
      "\n",
      "XGBoost Results:\n",
      "Mean Threshold: 2.2108 (±0.2307)\n",
      "Mean F1: 0.9486 (±0.0158)\n",
      "Mean AVG_Pre: 0.9772 (±0.0139)\n",
      "Mean ROC-AUC: 0.9987 (±0.0014)\n",
      "Mean PR-AUC: 0.9771 (±0.0139)\n",
      "Mean Precision: 0.9733 (±0.0117)\n",
      "Mean Recall: 0.9258 (±0.0303)\n",
      "Mean MCC: 0.9479 (±0.0159)\n",
      "Mean MAE: 0.3527 (±0.0019)\n",
      "\n",
      "Evaluating ANN...\n",
      "Fold 1 - Threshold: 3.3707, F1: 0.9217, AVG-Pre: 0.9271, ROC-AUC: 0.9770, PR-AUC: 0.9270, Precision: 0.9524, Recall: 0.8929, MAE: 0.3325, MCC: 0.9202\n",
      "Fold 2 - Threshold: 3.5581, F1: 0.8585, AVG-Pre: 0.9026, ROC-AUC: 0.9738, PR-AUC: 0.9024, Precision: 0.9286, Recall: 0.7982, MAE: 0.3543, MCC: 0.8577\n",
      "Fold 3 - Threshold: 3.3156, F1: 0.8517, AVG-Pre: 0.9302, ROC-AUC: 0.9925, PR-AUC: 0.9300, Precision: 0.8641, Recall: 0.8396, MAE: 0.3635, MCC: 0.8483\n",
      "Fold 4 - Threshold: 3.3468, F1: 0.8731, AVG-Pre: 0.9271, ROC-AUC: 0.9951, PR-AUC: 0.9268, Precision: 0.8958, Recall: 0.8515, MAE: 0.3476, MCC: 0.8706\n",
      "Fold 5 - Threshold: 3.3904, F1: 0.8410, AVG-Pre: 0.8970, ROC-AUC: 0.9841, PR-AUC: 0.8968, Precision: 0.9213, Recall: 0.7736, MAE: 0.3464, MCC: 0.8409\n",
      "\n",
      "ANN Results:\n",
      "Mean Threshold: 3.3963 (±0.0846)\n",
      "Mean F1: 0.8692 (±0.0282)\n",
      "Mean AVG_Pre: 0.9168 (±0.0141)\n",
      "Mean ROC-AUC: 0.9845 (±0.0083)\n",
      "Mean PR-AUC: 0.9166 (±0.0141)\n",
      "Mean Precision: 0.9124 (±0.0302)\n",
      "Mean Recall: 0.8312 (±0.0417)\n",
      "Mean MCC: 0.8675 (±0.0282)\n",
      "Mean MAE: 0.3489 (±0.0102)\n",
      "\n",
      "Overall Results:\n",
      "Random Forest:\n",
      "  Mean Threshold: 2.1740 (±0.0341)\n",
      "  Mean F1: 0.8563 (±0.0278)\n",
      "  Mean AVG_Pre: 0.9247 (±0.0223)\n",
      "  Mean ROC-AUC: 0.9972 (±0.0010)\n",
      "  Mean PR-AUC: 0.9243 (±0.0224)\n",
      "  Mean Precision: 0.8469 (±0.0558)\n",
      "  Mean Recall: 0.8724 (±0.0591)\n",
      "  Mean MCC: 0.8545 (±0.0273)\n",
      "  Mean MAE: 0.0994 (±0.0017)\n",
      "\n",
      "XGBoost:\n",
      "  Mean Threshold: 2.2108 (±0.2307)\n",
      "  Mean F1: 0.9486 (±0.0158)\n",
      "  Mean AVG_Pre: 0.9772 (±0.0139)\n",
      "  Mean ROC-AUC: 0.9987 (±0.0014)\n",
      "  Mean PR-AUC: 0.9771 (±0.0139)\n",
      "  Mean Precision: 0.9733 (±0.0117)\n",
      "  Mean Recall: 0.9258 (±0.0303)\n",
      "  Mean MCC: 0.9479 (±0.0159)\n",
      "  Mean MAE: 0.3527 (±0.0019)\n",
      "\n",
      "ANN:\n",
      "  Mean Threshold: 3.3963 (±0.0846)\n",
      "  Mean F1: 0.8692 (±0.0282)\n",
      "  Mean AVG_Pre: 0.9168 (±0.0141)\n",
      "  Mean ROC-AUC: 0.9845 (±0.0083)\n",
      "  Mean PR-AUC: 0.9166 (±0.0141)\n",
      "  Mean Precision: 0.9124 (±0.0302)\n",
      "  Mean Recall: 0.8312 (±0.0417)\n",
      "  Mean MCC: 0.8675 (±0.0282)\n",
      "  Mean MAE: 0.3489 (±0.0102)\n",
      "\n",
      "Mean Scores for Each Model (rounded to three decimal places):\n",
      "Threshold: [2.174, 2.211, 3.396]\n",
      "F1: [0.856, 0.949, 0.869]\n",
      "AVG-Prec: [0.925, 0.977, 0.917]\n",
      "ROC-AUC: [0.997, 0.999, 0.985]\n",
      "PR-AUC: [0.924, 0.977, 0.917]\n",
      "Precision: [0.847, 0.973, 0.912]\n",
      "Recall: [0.872, 0.926, 0.831]\n",
      "MCC: [0.855, 0.948, 0.868]\n",
      "MAE: [0.099, 0.353, 0.349]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, matthews_corrcoef, mean_absolute_error, precision_recall_curve, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    return optimal_threshold\n",
    "\n",
    "def convert_to_binary_test(y, threshold=2):\n",
    "    return (y > threshold).astype(int)\n",
    "    \n",
    "def convert_to_binary(y, threshold):\n",
    "    return (y > threshold).astype(int)\n",
    "\n",
    "# Initialize the KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the models in a dictionary\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=8, n_estimators=270, n_jobs=40),\n",
    "    'XGBoost': XGBRegressor(learning_rate=0.01, max_depth=7, colsample_bytree=0.73, gamma=1.96, min_child_weight=8.0, subsample=0.71, n_estimators=150),\n",
    "    'ANN': MLPRegressor(hidden_layer_sizes=50, activation='tanh', alpha=0.0070, learning_rate='invscaling', solver='sgd')\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation for each model\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    mae_scores, roc_auc_scores, pr_auc_scores, precision_scores, recall_scores, mcc_scores, avg_precision_scores, f1_scores, thresholds = [], [], [], [], [], [], [], [], []\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X_plec_train):\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_test = X_plec_train.iloc[train_index], X_plec_train.iloc[test_index]\n",
    "        y_train, y_test = y_plec_train.iloc[train_index], y_plec_train.iloc[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate regression metric (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Convert continuous true values to binary\n",
    "        #y_pred_binary = convert_to_binary(y_pred)\n",
    "        y_test_binary = convert_to_binary_test(y_test)        \n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_optimal_threshold(y_test_binary, y_pred)\n",
    "        thresholds.append(optimal_threshold)\n",
    "        \n",
    "        # Convert continuous predictions and true values to binary using optimal threshold\n",
    "        y_pred_binary = convert_to_binary(y_pred, optimal_threshold)\n",
    "        #y_test_binary = convert_to_binary(y_test, optimal_threshold)\n",
    "        \n",
    "        # Calculate classification metrics\n",
    "        roc_auc = roc_auc_score(y_test_binary, y_pred)\n",
    "        avg_precision = average_precision_score(y_test_binary, y_pred)\n",
    "        precision = precision_score(y_test_binary, y_pred_binary)\n",
    "        recall = recall_score(y_test_binary, y_pred_binary)\n",
    "        mcc = matthews_corrcoef(y_test_binary, y_pred_binary)\n",
    "        f1 = f1_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "        # Calculate PR-AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_test_binary, y_pred)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "        \n",
    "        # Append scores\n",
    "        mae_scores.append(mae)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        pr_auc_scores.append(pr_auc)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        mcc_scores.append(mcc)\n",
    "        avg_precision_scores.append(avg_precision)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold {fold} - Threshold: {optimal_threshold:.4f}, F1: {f1:.4f}, AVG-Pre: {avg_precision:.4f}, ROC-AUC: {roc_auc:.4f}, PR-AUC: {pr_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, MAE: {mae:.4f}, MCC: {mcc:.4f}\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate mean and standard deviation of scores\n",
    "    mean_threshold, std_threshold = np.mean(thresholds), np.std(thresholds)\n",
    "    mean_f1, std_f1 = np.mean(f1_scores), np.std(f1_scores)\n",
    "    mean_avg_pre, std_avg_pre = np.mean(avg_precision_scores), np.std(avg_precision_scores)\n",
    "    mean_roc_auc, std_roc_auc = np.mean(roc_auc_scores), np.std(roc_auc_scores)\n",
    "    mean_pr_auc, std_pr_auc = np.mean(pr_auc_scores), np.std(pr_auc_scores)\n",
    "    mean_precision, std_precision = np.mean(precision_scores), np.std(precision_scores)\n",
    "    mean_recall, std_recall = np.mean(recall_scores), np.std(recall_scores)\n",
    "    mean_mcc, std_mcc = np.mean(mcc_scores), np.std(mcc_scores)\n",
    "    mean_mae, std_mae = np.mean(mae_scores), np.std(mae_scores)\n",
    "    \n",
    "    results[model_name] = (mean_threshold, std_threshold,\n",
    "                           mean_f1, std_f1,\n",
    "                           mean_avg_pre, std_avg_pre, \n",
    "                           mean_roc_auc, std_roc_auc,\n",
    "                           mean_pr_auc, std_pr_auc,\n",
    "                           mean_precision, std_precision, \n",
    "                           mean_recall, std_recall,\n",
    "                           mean_mcc, std_mcc,\n",
    "                           mean_mae, std_mae)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Mean Threshold: {mean_threshold:.4f} (±{std_threshold:.4f})\")\n",
    "    print(f\"Mean F1: {mean_f1:.4f} (±{std_f1:.4f})\")\n",
    "    print(f\"Mean AVG_Pre: {mean_avg_pre:.4f} (±{std_avg_pre:.4f})\")\n",
    "    print(f\"Mean ROC-AUC: {mean_roc_auc:.4f} (±{std_roc_auc:.4f})\")\n",
    "    print(f\"Mean PR-AUC: {mean_pr_auc:.4f} (±{std_pr_auc:.4f})\")\n",
    "    print(f\"Mean Precision: {mean_precision:.4f} (±{std_precision:.4f})\")\n",
    "    print(f\"Mean Recall: {mean_recall:.4f} (±{std_recall:.4f})\")\n",
    "    print(f\"Mean MCC: {mean_mcc:.4f} (±{std_mcc:.4f})\")\n",
    "    print(f\"Mean MAE: {mean_mae:.4f} (±{std_mae:.4f})\\n\")\n",
    "\n",
    "# Print overall results\n",
    "print(\"Overall Results:\")\n",
    "for model_name, scores in results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Mean Threshold: {scores[0]:.4f} (±{scores[1]:.4f})\")\n",
    "    print(f\"  Mean F1: {scores[2]:.4f} (±{scores[3]:.4f})\")\n",
    "    print(f\"  Mean AVG_Pre: {scores[4]:.4f} (±{scores[5]:.4f})\")\n",
    "    print(f\"  Mean ROC-AUC: {scores[6]:.4f} (±{scores[7]:.4f})\")\n",
    "    print(f\"  Mean PR-AUC: {scores[8]:.4f} (±{scores[9]:.4f})\")\n",
    "    print(f\"  Mean Precision: {scores[10]:.4f} (±{scores[11]:.4f})\")\n",
    "    print(f\"  Mean Recall: {scores[12]:.4f} (±{scores[13]:.4f})\")\n",
    "    print(f\"  Mean MCC: {scores[14]:.4f} (±{scores[15]:.4f})\")\n",
    "    print(f\"  Mean MAE: {scores[16]:.4f} (±{scores[17]:.4f})\")\n",
    "    print()\n",
    "\n",
    "# Collect mean scores for each model\n",
    "mean_scores = {metric: [] for metric in ['Threshold', 'F1', 'AVG-Prec', 'ROC-AUC', 'PR-AUC', 'Precision', 'Recall', 'MCC', 'MAE']}\n",
    "\n",
    "for model_name, scores in results.items():\n",
    "    mean_scores['Threshold'].append(round(scores[0], 3))\n",
    "    mean_scores['F1'].append(round(scores[2], 3))\n",
    "    mean_scores['AVG-Prec'].append(round(scores[4], 3))\n",
    "    mean_scores['ROC-AUC'].append(round(scores[6], 3))\n",
    "    mean_scores['PR-AUC'].append(round(scores[8], 3))\n",
    "    mean_scores['Precision'].append(round(scores[10], 3))\n",
    "    mean_scores['Recall'].append(round(scores[12], 3))\n",
    "    mean_scores['MCC'].append(round(scores[14], 3))\n",
    "    mean_scores['MAE'].append(round(scores[16], 3))\n",
    "\n",
    "print(\"Mean Scores for Each Model (rounded to three decimal places):\")\n",
    "for metric, scores in mean_scores.items():\n",
    "    print(f\"{metric}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c012c8e-1732-4148-949d-107336f4c337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest...\n",
      "Fold 1 - Threshold: 2.2077, F1: 0.8889, AVG-Pre: 0.9539, ROC-AUC: 0.9983, PR-AUC: 0.9537, Precision: 0.9231, Recall: 0.8571, MAE: 0.1111, MCC: 0.8868\n",
      "Fold 2 - Threshold: 2.1855, F1: 0.8776, AVG-Pre: 0.9337, ROC-AUC: 0.9965, PR-AUC: 0.9334, Precision: 0.8455, Recall: 0.9123, MAE: 0.1110, MCC: 0.8750\n",
      "Fold 3 - Threshold: 2.1906, F1: 0.9124, AVG-Pre: 0.9683, ROC-AUC: 0.9990, PR-AUC: 0.9682, Precision: 0.8919, Recall: 0.9340, MAE: 0.1102, MCC: 0.9106\n",
      "Fold 4 - Threshold: 2.1812, F1: 0.9128, AVG-Pre: 0.9608, ROC-AUC: 0.9983, PR-AUC: 0.9606, Precision: 0.9468, Recall: 0.8812, MAE: 0.1104, MCC: 0.9115\n",
      "Fold 5 - Threshold: 2.2036, F1: 0.9038, AVG-Pre: 0.9507, ROC-AUC: 0.9924, PR-AUC: 0.9506, Precision: 0.9216, Recall: 0.8868, MAE: 0.1098, MCC: 0.9018\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Threshold: 2.1937 (±0.0103)\n",
      "Mean F1: 0.8991 (±0.0138)\n",
      "Mean AVG_Pre: 0.9535 (±0.0116)\n",
      "Mean ROC-AUC: 0.9969 (±0.0024)\n",
      "Mean PR-AUC: 0.9533 (±0.0116)\n",
      "Mean Precision: 0.9058 (±0.0348)\n",
      "Mean Recall: 0.8943 (±0.0265)\n",
      "Mean MCC: 0.8971 (±0.0142)\n",
      "Mean MAE: 0.1105 (±0.0005)\n",
      "\n",
      "Evaluating XGBoost...\n",
      "Fold 1 - Threshold: 2.1044, F1: 0.9596, AVG-Pre: 0.9818, ROC-AUC: 0.9982, PR-AUC: 0.9819, Precision: 0.9640, Recall: 0.9554, MAE: 0.3519, MCC: 0.9586\n",
      "Fold 2 - Threshold: 2.2319, F1: 0.9558, AVG-Pre: 0.9741, ROC-AUC: 0.9905, PR-AUC: 0.9742, Precision: 0.9643, Recall: 0.9474, MAE: 0.3513, MCC: 0.9547\n",
      "Fold 3 - Threshold: 2.3429, F1: 0.9810, AVG-Pre: 0.9893, ROC-AUC: 0.9942, PR-AUC: 0.9895, Precision: 0.9904, Recall: 0.9717, MAE: 0.3529, MCC: 0.9805\n",
      "Fold 4 - Threshold: 2.2393, F1: 0.9463, AVG-Pre: 0.9850, ROC-AUC: 0.9994, PR-AUC: 0.9849, Precision: 0.9327, Recall: 0.9604, MAE: 0.3518, MCC: 0.9452\n",
      "Fold 5 - Threshold: 2.3013, F1: 0.9612, AVG-Pre: 0.9818, ROC-AUC: 0.9940, PR-AUC: 0.9821, Precision: 0.9900, Recall: 0.9340, MAE: 0.3518, MCC: 0.9607\n",
      "\n",
      "XGBoost Results:\n",
      "Mean Threshold: 2.2440 (±0.0809)\n",
      "Mean F1: 0.9608 (±0.0113)\n",
      "Mean AVG_Pre: 0.9824 (±0.0050)\n",
      "Mean ROC-AUC: 0.9953 (±0.0032)\n",
      "Mean PR-AUC: 0.9825 (±0.0050)\n",
      "Mean Precision: 0.9683 (±0.0213)\n",
      "Mean Recall: 0.9538 (±0.0127)\n",
      "Mean MCC: 0.9599 (±0.0116)\n",
      "Mean MAE: 0.3519 (±0.0005)\n",
      "\n",
      "Evaluating ANN...\n",
      "Fold 1 - Threshold: 2.8752, F1: 0.7245, AVG-Pre: 0.7572, ROC-AUC: 0.9547, PR-AUC: 0.7567, Precision: 0.8452, Recall: 0.6339, MAE: 0.2548, MCC: 0.7263\n",
      "Fold 2 - Threshold: 3.1735, F1: 0.7164, AVG-Pre: 0.7597, ROC-AUC: 0.9579, PR-AUC: 0.7591, Precision: 0.8276, Recall: 0.6316, MAE: 0.3071, MCC: 0.7169\n",
      "Fold 3 - Threshold: 3.0906, F1: 0.8000, AVG-Pre: 0.8526, ROC-AUC: 0.9855, PR-AUC: 0.8523, Precision: 0.8764, Recall: 0.7358, MAE: 0.2975, MCC: 0.7988\n",
      "Fold 4 - Threshold: 3.1446, F1: 0.7037, AVG-Pre: 0.7360, ROC-AUC: 0.9490, PR-AUC: 0.7354, Precision: 0.9344, Recall: 0.5644, MAE: 0.2652, MCC: 0.7218\n",
      "Fold 5 - Threshold: 3.1963, F1: 0.7701, AVG-Pre: 0.7941, ROC-AUC: 0.9504, PR-AUC: 0.7937, Precision: 0.8889, Recall: 0.6792, MAE: 0.2874, MCC: 0.7725\n",
      "\n",
      "ANN Results:\n",
      "Mean Threshold: 3.0960 (±0.1160)\n",
      "Mean F1: 0.7429 (±0.0363)\n",
      "Mean AVG_Pre: 0.7799 (±0.0408)\n",
      "Mean ROC-AUC: 0.9595 (±0.0134)\n",
      "Mean PR-AUC: 0.7794 (±0.0409)\n",
      "Mean Precision: 0.8745 (±0.0370)\n",
      "Mean Recall: 0.6490 (±0.0568)\n",
      "Mean MCC: 0.7473 (±0.0326)\n",
      "Mean MAE: 0.2824 (±0.0196)\n",
      "\n",
      "Overall Results:\n",
      "Random Forest:\n",
      "  Mean Threshold: 2.1937 (±0.0103)\n",
      "  Mean F1: 0.8991 (±0.0138)\n",
      "  Mean AVG_Pre: 0.9535 (±0.0116)\n",
      "  Mean ROC-AUC: 0.9969 (±0.0024)\n",
      "  Mean PR-AUC: 0.9533 (±0.0116)\n",
      "  Mean Precision: 0.9058 (±0.0348)\n",
      "  Mean Recall: 0.8943 (±0.0265)\n",
      "  Mean MCC: 0.8971 (±0.0142)\n",
      "  Mean MAE: 0.1105 (±0.0005)\n",
      "\n",
      "XGBoost:\n",
      "  Mean Threshold: 2.2440 (±0.0809)\n",
      "  Mean F1: 0.9608 (±0.0113)\n",
      "  Mean AVG_Pre: 0.9824 (±0.0050)\n",
      "  Mean ROC-AUC: 0.9953 (±0.0032)\n",
      "  Mean PR-AUC: 0.9825 (±0.0050)\n",
      "  Mean Precision: 0.9683 (±0.0213)\n",
      "  Mean Recall: 0.9538 (±0.0127)\n",
      "  Mean MCC: 0.9599 (±0.0116)\n",
      "  Mean MAE: 0.3519 (±0.0005)\n",
      "\n",
      "ANN:\n",
      "  Mean Threshold: 3.0960 (±0.1160)\n",
      "  Mean F1: 0.7429 (±0.0363)\n",
      "  Mean AVG_Pre: 0.7799 (±0.0408)\n",
      "  Mean ROC-AUC: 0.9595 (±0.0134)\n",
      "  Mean PR-AUC: 0.7794 (±0.0409)\n",
      "  Mean Precision: 0.8745 (±0.0370)\n",
      "  Mean Recall: 0.6490 (±0.0568)\n",
      "  Mean MCC: 0.7473 (±0.0326)\n",
      "  Mean MAE: 0.2824 (±0.0196)\n",
      "\n",
      "Mean Scores for Each Model (rounded to three decimal places):\n",
      "Threshold: [2.194, 2.244, 3.096]\n",
      "F1: [0.899, 0.961, 0.743]\n",
      "AVG-Prec: [0.953, 0.982, 0.78]\n",
      "ROC-AUC: [0.997, 0.995, 0.959]\n",
      "PR-AUC: [0.953, 0.983, 0.779]\n",
      "Precision: [0.906, 0.968, 0.875]\n",
      "Recall: [0.894, 0.954, 0.649]\n",
      "MCC: [0.897, 0.96, 0.747]\n",
      "MAE: [0.11, 0.352, 0.282]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, matthews_corrcoef, mean_absolute_error, precision_recall_curve, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    return optimal_threshold\n",
    "\n",
    "def convert_to_binary_test(y, threshold=2):\n",
    "    return (y > threshold).astype(int)\n",
    "    \n",
    "def convert_to_binary(y, threshold):\n",
    "    return (y > threshold).astype(int)\n",
    "\n",
    "# Initialize the KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the models in a dictionary\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=8, n_estimators=270, n_jobs=40),\n",
    "    'XGBoost': XGBRegressor(learning_rate=0.01, max_depth=7, colsample_bytree=0.73, gamma=1.96, min_child_weight=8.0, subsample=0.71, n_estimators=150),\n",
    "    'ANN': MLPRegressor(hidden_layer_sizes=50, activation='tanh', alpha=0.0070, learning_rate='invscaling', solver='sgd')\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation for each model\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    mae_scores, roc_auc_scores, pr_auc_scores, precision_scores, recall_scores, mcc_scores, avg_precision_scores, f1_scores, thresholds = [], [], [], [], [], [], [], [], []\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X_grid_train):\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_test = X_grid_train.iloc[train_index], X_grid_train.iloc[test_index]\n",
    "        y_train, y_test = y_grid_train.iloc[train_index], y_grid_train.iloc[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate regression metric (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Convert continuous true values to binary\n",
    "        #y_pred_binary = convert_to_binary(y_pred)\n",
    "        y_test_binary = convert_to_binary_test(y_test)        \n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_optimal_threshold(y_test_binary, y_pred)\n",
    "        thresholds.append(optimal_threshold)\n",
    "        \n",
    "        # Convert continuous predictions and true values to binary using optimal threshold\n",
    "        y_pred_binary = convert_to_binary(y_pred, optimal_threshold)\n",
    "        #y_test_binary = convert_to_binary(y_test, optimal_threshold)\n",
    "        \n",
    "        # Calculate classification metrics\n",
    "        roc_auc = roc_auc_score(y_test_binary, y_pred)\n",
    "        avg_precision = average_precision_score(y_test_binary, y_pred)\n",
    "        precision = precision_score(y_test_binary, y_pred_binary)\n",
    "        recall = recall_score(y_test_binary, y_pred_binary)\n",
    "        mcc = matthews_corrcoef(y_test_binary, y_pred_binary)\n",
    "        f1 = f1_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "        # Calculate PR-AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_test_binary, y_pred)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "        \n",
    "        # Append scores\n",
    "        mae_scores.append(mae)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        pr_auc_scores.append(pr_auc)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        mcc_scores.append(mcc)\n",
    "        avg_precision_scores.append(avg_precision)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold {fold} - Threshold: {optimal_threshold:.4f}, F1: {f1:.4f}, AVG-Pre: {avg_precision:.4f}, ROC-AUC: {roc_auc:.4f}, PR-AUC: {pr_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, MAE: {mae:.4f}, MCC: {mcc:.4f}\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate mean and standard deviation of scores\n",
    "    mean_threshold, std_threshold = np.mean(thresholds), np.std(thresholds)\n",
    "    mean_f1, std_f1 = np.mean(f1_scores), np.std(f1_scores)\n",
    "    mean_avg_pre, std_avg_pre = np.mean(avg_precision_scores), np.std(avg_precision_scores)\n",
    "    mean_roc_auc, std_roc_auc = np.mean(roc_auc_scores), np.std(roc_auc_scores)\n",
    "    mean_pr_auc, std_pr_auc = np.mean(pr_auc_scores), np.std(pr_auc_scores)\n",
    "    mean_precision, std_precision = np.mean(precision_scores), np.std(precision_scores)\n",
    "    mean_recall, std_recall = np.mean(recall_scores), np.std(recall_scores)\n",
    "    mean_mcc, std_mcc = np.mean(mcc_scores), np.std(mcc_scores)\n",
    "    mean_mae, std_mae = np.mean(mae_scores), np.std(mae_scores)\n",
    "    \n",
    "    results[model_name] = (mean_threshold, std_threshold,\n",
    "                           mean_f1, std_f1,\n",
    "                           mean_avg_pre, std_avg_pre, \n",
    "                           mean_roc_auc, std_roc_auc,\n",
    "                           mean_pr_auc, std_pr_auc,\n",
    "                           mean_precision, std_precision, \n",
    "                           mean_recall, std_recall,\n",
    "                           mean_mcc, std_mcc,\n",
    "                           mean_mae, std_mae)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Mean Threshold: {mean_threshold:.4f} (±{std_threshold:.4f})\")\n",
    "    print(f\"Mean F1: {mean_f1:.4f} (±{std_f1:.4f})\")\n",
    "    print(f\"Mean AVG_Pre: {mean_avg_pre:.4f} (±{std_avg_pre:.4f})\")\n",
    "    print(f\"Mean ROC-AUC: {mean_roc_auc:.4f} (±{std_roc_auc:.4f})\")\n",
    "    print(f\"Mean PR-AUC: {mean_pr_auc:.4f} (±{std_pr_auc:.4f})\")\n",
    "    print(f\"Mean Precision: {mean_precision:.4f} (±{std_precision:.4f})\")\n",
    "    print(f\"Mean Recall: {mean_recall:.4f} (±{std_recall:.4f})\")\n",
    "    print(f\"Mean MCC: {mean_mcc:.4f} (±{std_mcc:.4f})\")\n",
    "    print(f\"Mean MAE: {mean_mae:.4f} (±{std_mae:.4f})\\n\")\n",
    "\n",
    "# Print overall results\n",
    "print(\"Overall Results:\")\n",
    "for model_name, scores in results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Mean Threshold: {scores[0]:.4f} (±{scores[1]:.4f})\")\n",
    "    print(f\"  Mean F1: {scores[2]:.4f} (±{scores[3]:.4f})\")\n",
    "    print(f\"  Mean AVG_Pre: {scores[4]:.4f} (±{scores[5]:.4f})\")\n",
    "    print(f\"  Mean ROC-AUC: {scores[6]:.4f} (±{scores[7]:.4f})\")\n",
    "    print(f\"  Mean PR-AUC: {scores[8]:.4f} (±{scores[9]:.4f})\")\n",
    "    print(f\"  Mean Precision: {scores[10]:.4f} (±{scores[11]:.4f})\")\n",
    "    print(f\"  Mean Recall: {scores[12]:.4f} (±{scores[13]:.4f})\")\n",
    "    print(f\"  Mean MCC: {scores[14]:.4f} (±{scores[15]:.4f})\")\n",
    "    print(f\"  Mean MAE: {scores[16]:.4f} (±{scores[17]:.4f})\")\n",
    "    print()\n",
    "\n",
    "# Collect mean scores for each model\n",
    "mean_scores = {metric: [] for metric in ['Threshold', 'F1', 'AVG-Prec', 'ROC-AUC', 'PR-AUC', 'Precision', 'Recall', 'MCC', 'MAE']}\n",
    "\n",
    "for model_name, scores in results.items():\n",
    "    mean_scores['Threshold'].append(round(scores[0], 3))\n",
    "    mean_scores['F1'].append(round(scores[2], 3))\n",
    "    mean_scores['AVG-Prec'].append(round(scores[4], 3))\n",
    "    mean_scores['ROC-AUC'].append(round(scores[6], 3))\n",
    "    mean_scores['PR-AUC'].append(round(scores[8], 3))\n",
    "    mean_scores['Precision'].append(round(scores[10], 3))\n",
    "    mean_scores['Recall'].append(round(scores[12], 3))\n",
    "    mean_scores['MCC'].append(round(scores[14], 3))\n",
    "    mean_scores['MAE'].append(round(scores[16], 3))\n",
    "\n",
    "print(\"Mean Scores for Each Model (rounded to three decimal places):\")\n",
    "for metric, scores in mean_scores.items():\n",
    "    print(f\"{metric}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a0ed1-819f-4fb5-bc57-e3da059efa5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb3af3-3ea3-4ea3-8649-337937d97cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e94bc-b5aa-435b-a881-25bb65191064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa2643-25fd-4310-9fd0-92047e9463a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
