{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936617da-a225-40c5-a6a0-dca31a7dbe03",
   "metadata": {},
   "source": [
    "# **Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7cbb8-5567-4777-90f3-b8fc77e023af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import oddt\n",
    "from oddt.fingerprints import PLEC\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import parallel_backend\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import deepchem as dc\n",
    "from deepchem.utils import download_url, load_from_disk\n",
    "from deepchem.utils.vina_utils import prepare_inputs\n",
    "from deepchem.models import AtomicConvModel\n",
    "from deepchem.feat import RdkitGridFeaturizer\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6361b9-f78a-4aa1-a9cd-8352dbc58d3f",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d21fdd-7669-42f7-8a23-9db65da43f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set true actives\n",
    "plec_train_true_actives = pd.read_csv('Path_to_csv')\n",
    "grid_train_true_actives = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "# test sets true actives\n",
    "plec_test_true_actives = pd.read_csv('Path_to_csv')\n",
    "grid_test_true_actives = pd.read_csv('Path_to_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6714d-bd99-43b3-a4c8-6132f6960df4",
   "metadata": {},
   "source": [
    "# **Load Decoys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d95a3-63e4-47f4-9882-c75196e26d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set random_decoys\n",
    "plec_train_random_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_train_random_decoys = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "# test sets random_decoys\n",
    "plec_test_random_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_test_random_decoys = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "\n",
    "# training set deepcoy decoys\n",
    "plec_train_deepcoy_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_train_deepcoy_decoys = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "# test sets deepcoy decoys\n",
    "plec_test_deepcoy_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_test_deepcoy_decoys = pd.read_csv('Path_to_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d13e15-a27a-40ef-9924-759e2cc2cbbb",
   "metadata": {},
   "source": [
    "# **Cross validation with Randoom deocys in the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a246e485-62f6-4340-87dc-235b3e5dc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_train = pd.concat([plec_train_true_actives,plec_train_random_decoys])\n",
    "grid_train = pd.concat([grid_train_true_actives,grid_train_random_decoys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "354b8c9d-168e-4a81-9dec-402189725e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X_plec_train, y_plec_train = plec_train.drop(['class', 'potency','index'], axis= 1), plec_train['class']\n",
    "X_grid_train, y_grid_train = grid_train.drop(['class', 'potency'], axis= 1), grid_train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2296fdbf-61e9-4a91-8804-3f226941385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_train_reset = plec_train.reset_index(drop=True)\n",
    "grid_train_reset = grid_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e90b61d7-b83d-4cc5-8937-2b7851fe2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plec_train, y_plec_train = plec_train_reset.drop(['class', 'potency','index'], axis= 1), plec_train_reset['class']\n",
    "X_grid_train, y_grid_train = grid_train_reset.drop(['class', 'potency'], axis= 1), grid_train_reset['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7ab73423-14f7-4885-ae91-01bdb238b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_plec_train = y_plec_train.map({'active': 1, 'inactive': 0})\n",
    "y_grid_train = y_grid_train.map({'active': 1, 'inactive': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f1c5acf-28dd-45a9-a3f2-a98c0b6f8a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "22684    0\n",
       "22685    0\n",
       "22686    0\n",
       "22687    0\n",
       "22688    0\n",
       "Name: class, Length: 22689, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_plec_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18843342-7087-4b16-9c76-b16c70959b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest...\n",
      "Fold 1 - Optimal Threshold: 0.024, Avg Precision: 0.872, ROC-AUC: 0.990, PR-AUC: 0.871, Precision: 0.330, Recall: 0.944, MCC: 0.543, F1: 0.489\n",
      "Fold 2 - Optimal Threshold: 0.025, Avg Precision: 0.919, ROC-AUC: 0.995, PR-AUC: 0.919, Precision: 0.433, Recall: 0.963, MCC: 0.635, F1: 0.598\n",
      "Fold 3 - Optimal Threshold: 0.026, Avg Precision: 0.829, ROC-AUC: 0.977, PR-AUC: 0.829, Precision: 0.411, Recall: 0.880, MCC: 0.589, F1: 0.560\n",
      "Fold 4 - Optimal Threshold: 0.026, Avg Precision: 0.833, ROC-AUC: 0.975, PR-AUC: 0.832, Precision: 0.254, Recall: 0.935, MCC: 0.468, F1: 0.399\n",
      "Fold 5 - Optimal Threshold: 0.028, Avg Precision: 0.803, ROC-AUC: 0.957, PR-AUC: 0.803, Precision: 0.247, Recall: 0.916, MCC: 0.456, F1: 0.389\n",
      "Evaluating XGBoost...\n",
      "Fold 1 - Optimal Threshold: 0.138, Avg Precision: 0.932, ROC-AUC: 0.992, PR-AUC: 0.932, Precision: 0.457, Recall: 0.972, MCC: 0.656, F1: 0.621\n",
      "Fold 2 - Optimal Threshold: 0.183, Avg Precision: 0.983, ROC-AUC: 0.999, PR-AUC: 0.983, Precision: 0.797, Recall: 0.981, MCC: 0.881, F1: 0.880\n",
      "Fold 3 - Optimal Threshold: 0.133, Avg Precision: 0.902, ROC-AUC: 0.982, PR-AUC: 0.902, Precision: 0.335, Recall: 0.963, MCC: 0.554, F1: 0.498\n",
      "Fold 4 - Optimal Threshold: 0.187, Avg Precision: 0.894, ROC-AUC: 0.984, PR-AUC: 0.893, Precision: 0.588, Recall: 0.898, MCC: 0.719, F1: 0.711\n",
      "Fold 5 - Optimal Threshold: 0.153, Avg Precision: 0.899, ROC-AUC: 0.991, PR-AUC: 0.898, Precision: 0.364, Recall: 0.953, MCC: 0.576, F1: 0.527\n",
      "Evaluating ANN...\n",
      "Fold 1 - Optimal Threshold: 0.069, Avg Precision: 0.592, ROC-AUC: 0.882, PR-AUC: 0.591, Precision: 0.189, Recall: 0.667, MCC: 0.329, F1: 0.295\n",
      "Fold 2 - Optimal Threshold: 0.108, Avg Precision: 0.501, ROC-AUC: 0.874, PR-AUC: 0.494, Precision: 0.262, Recall: 0.704, MCC: 0.408, F1: 0.382\n",
      "Fold 3 - Optimal Threshold: 0.081, Avg Precision: 0.583, ROC-AUC: 0.826, PR-AUC: 0.582, Precision: 0.234, Recall: 0.620, MCC: 0.358, F1: 0.340\n",
      "Fold 4 - Optimal Threshold: 0.016, Avg Precision: 0.211, ROC-AUC: 0.839, PR-AUC: 0.208, Precision: 0.061, Recall: 0.815, MCC: 0.166, F1: 0.113\n",
      "Fold 5 - Optimal Threshold: 0.018, Avg Precision: 0.537, ROC-AUC: 0.914, PR-AUC: 0.535, Precision: 0.103, Recall: 0.832, MCC: 0.254, F1: 0.184\n",
      "\n",
      "Random Forest:\n",
      "Mean Optimal Threshold: 0.026, Std Dev: 0.001\n",
      "Mean Average Precision: 0.851, Std Dev: 0.040\n",
      "Mean ROC-AUC: 0.979, Std Dev: 0.013\n",
      "Mean PR-AUC: 0.851, Std Dev: 0.041\n",
      "Mean Precision: 0.335, Std Dev: 0.077\n",
      "Mean Recall: 0.928, Std Dev: 0.028\n",
      "Mean MCC: 0.538, Std Dev: 0.069\n",
      "Mean F1 Score: 0.487, Std Dev: 0.084\n",
      "\n",
      "XGBoost:\n",
      "Mean Optimal Threshold: 0.159, Std Dev: 0.022\n",
      "Mean Average Precision: 0.922, Std Dev: 0.034\n",
      "Mean ROC-AUC: 0.989, Std Dev: 0.006\n",
      "Mean PR-AUC: 0.922, Std Dev: 0.034\n",
      "Mean Precision: 0.508, Std Dev: 0.169\n",
      "Mean Recall: 0.954, Std Dev: 0.029\n",
      "Mean MCC: 0.677, Std Dev: 0.118\n",
      "Mean F1 Score: 0.647, Std Dev: 0.138\n",
      "\n",
      "ANN:\n",
      "Mean Optimal Threshold: 0.058, Std Dev: 0.036\n",
      "Mean Average Precision: 0.485, Std Dev: 0.141\n",
      "Mean ROC-AUC: 0.867, Std Dev: 0.032\n",
      "Mean PR-AUC: 0.482, Std Dev: 0.142\n",
      "Mean Precision: 0.170, Std Dev: 0.077\n",
      "Mean Recall: 0.727, Std Dev: 0.083\n",
      "Mean MCC: 0.303, Std Dev: 0.085\n",
      "Mean F1 Score: 0.263, Std Dev: 0.100\n",
      "\n",
      "Mean Metrics for Each Model (rounded to three decimal places):\n",
      "\n",
      "Random Forest:\n",
      "Mean Optimal Threshold: 0.026, Std Dev: 0.001\n",
      "Mean Average Precision: 0.851, Std Dev: 0.040\n",
      "Mean ROC-AUC: 0.979, Std Dev: 0.013\n",
      "Mean PR-AUC: 0.851, Std Dev: 0.041\n",
      "Mean Precision: 0.335, Std Dev: 0.077\n",
      "Mean Recall: 0.928, Std Dev: 0.028\n",
      "Mean MCC: 0.538, Std Dev: 0.069\n",
      "Mean F1 Score: 0.487, Std Dev: 0.084\n",
      "\n",
      "XGBoost:\n",
      "Mean Optimal Threshold: 0.1589999943971634, Std Dev: 0.022\n",
      "Mean Average Precision: 0.922, Std Dev: 0.034\n",
      "Mean ROC-AUC: 0.989, Std Dev: 0.006\n",
      "Mean PR-AUC: 0.922, Std Dev: 0.034\n",
      "Mean Precision: 0.508, Std Dev: 0.169\n",
      "Mean Recall: 0.954, Std Dev: 0.029\n",
      "Mean MCC: 0.677, Std Dev: 0.118\n",
      "Mean F1 Score: 0.647, Std Dev: 0.138\n",
      "\n",
      "ANN:\n",
      "Mean Optimal Threshold: 0.058, Std Dev: 0.036\n",
      "Mean Average Precision: 0.485, Std Dev: 0.141\n",
      "Mean ROC-AUC: 0.867, Std Dev: 0.032\n",
      "Mean PR-AUC: 0.482, Std Dev: 0.142\n",
      "Mean Precision: 0.17, Std Dev: 0.077\n",
      "Mean Recall: 0.727, Std Dev: 0.083\n",
      "Mean MCC: 0.303, Std Dev: 0.085\n",
      "Mean F1 Score: 0.263, Std Dev: 0.100\n",
      "\n",
      "Mean Metric Scores for Each Model:\n",
      "Optimal Threshold: [0.026, 0.159, 0.058]\n",
      "Average Precision: [0.851, 0.922, 0.485]\n",
      "ROC-AUC: [0.979, 0.989, 0.867]\n",
      "PR-AUC: [0.851, 0.922, 0.482]\n",
      "Precision: [0.335, 0.508, 0.17]\n",
      "Recall: [0.928, 0.954, 0.727]\n",
      "MCC: [0.538, 0.677, 0.303]\n",
      "F1 Score: [0.487, 0.647, 0.263]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score, precision_score,\n",
    "    recall_score, matthews_corrcoef, roc_curve, precision_recall_curve,\n",
    "    f1_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred_prob):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    return thresholds[optimal_idx]\n",
    "\n",
    "# Initialize the StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Define the models in a dictionary\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=8, n_estimators=270, n_jobs=40),\n",
    "    'XGBoost': XGBClassifier(learning_rate=0.01, max_depth=7, colsample_bytree=0.73, gamma=1.96, min_child_weight=8, subsample=0.71, n_estimators=150),\n",
    "    'ANN': MLPClassifier(hidden_layer_sizes=(50,), activation='tanh', alpha=0.0070, learning_rate='invscaling', solver='sgd')\n",
    "}\n",
    "\n",
    "# Perform stratified 5-fold cross-validation for each model\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    metrics = {\n",
    "        'Optimal Threshold': [],\n",
    "        'Average Precision': [],\n",
    "        'ROC-AUC': [],\n",
    "        'PR-AUC': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'MCC': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in skf.split(X_plec_train, y_plec_train):\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_test = X_plec_train.iloc[train_index], X_plec_train.iloc[test_index]\n",
    "        y_train, y_test = y_plec_train[train_index], y_plec_train[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities on the validation set\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_optimal_threshold(y_test, y_pred_prob)\n",
    "        \n",
    "        # Make predictions using the optimal threshold\n",
    "        y_pred = (y_pred_prob >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_precision = average_precision_score(y_test, y_pred_prob)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Calculate PR-AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "        \n",
    "        # Store metrics\n",
    "        metrics['Optimal Threshold'].append(optimal_threshold)\n",
    "        metrics['Average Precision'].append(avg_precision)\n",
    "        metrics['ROC-AUC'].append(roc_auc)\n",
    "        metrics['PR-AUC'].append(pr_auc)\n",
    "        metrics['Precision'].append(precision)\n",
    "        metrics['Recall'].append(recall)\n",
    "        metrics['MCC'].append(mcc)\n",
    "        metrics['F1 Score'].append(f1)\n",
    "        \n",
    "        print(f\"Fold {fold} - Optimal Threshold: {optimal_threshold:.3f}, Avg Precision: {avg_precision:.3f}, ROC-AUC: {roc_auc:.3f}, PR-AUC: {pr_auc:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, MCC: {mcc:.3f}, F1: {f1:.3f}\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate mean and standard deviation of each metric\n",
    "    results[model_name] = {metric: (np.mean(values), np.std(values)) for metric, values in metrics.items()}\n",
    "\n",
    "# Print overall results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        print(f\"Mean {metric}: {mean:.3f}, Std Dev: {std:.3f}\")\n",
    "\n",
    "# Print mean metrics for each model\n",
    "print(\"\\nMean Metrics for Each Model (rounded to three decimal places):\")\n",
    "mean_metrics = {metric: [] for metric in metrics.keys()}\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        mean_rounded = round(mean, 3)\n",
    "        mean_metrics[metric].append(mean_rounded)\n",
    "        print(f\"Mean {metric}: {mean_rounded}, Std Dev: {std:.3f}\")\n",
    "\n",
    "print(\"\\nMean Metric Scores for Each Model:\")\n",
    "for metric, scores in mean_metrics.items():\n",
    "    print(f\"{metric}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e608764a-6209-4086-82da-7f145e716a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest...\n",
      "Fold 1 - Optimal Threshold: 0.028, Avg Precision: 0.785, ROC-AUC: 0.955, PR-AUC: 0.785, Precision: 0.271, Recall: 0.861, MCC: 0.464, F1: 0.412\n",
      "Fold 2 - Optimal Threshold: 0.027, Avg Precision: 0.859, ROC-AUC: 0.986, PR-AUC: 0.858, Precision: 0.240, Recall: 0.954, MCC: 0.459, F1: 0.384\n",
      "Fold 3 - Optimal Threshold: 0.028, Avg Precision: 0.769, ROC-AUC: 0.949, PR-AUC: 0.769, Precision: 0.271, Recall: 0.824, MCC: 0.453, F1: 0.407\n",
      "Fold 4 - Optimal Threshold: 0.032, Avg Precision: 0.777, ROC-AUC: 0.927, PR-AUC: 0.777, Precision: 0.318, Recall: 0.824, MCC: 0.495, F1: 0.459\n",
      "Fold 5 - Optimal Threshold: 0.031, Avg Precision: 0.663, ROC-AUC: 0.884, PR-AUC: 0.663, Precision: 0.132, Recall: 0.813, MCC: 0.294, F1: 0.227\n",
      "Evaluating XGBoost...\n",
      "Fold 1 - Optimal Threshold: 0.192, Avg Precision: 0.930, ROC-AUC: 0.978, PR-AUC: 0.930, Precision: 0.789, Recall: 0.935, MCC: 0.855, F1: 0.856\n",
      "Fold 2 - Optimal Threshold: 0.153, Avg Precision: 0.969, ROC-AUC: 0.999, PR-AUC: 0.969, Precision: 0.592, Recall: 0.981, MCC: 0.756, F1: 0.739\n",
      "Fold 3 - Optimal Threshold: 0.170, Avg Precision: 0.920, ROC-AUC: 0.967, PR-AUC: 0.920, Precision: 0.671, Recall: 0.926, MCC: 0.783, F1: 0.778\n",
      "Fold 4 - Optimal Threshold: 0.201, Avg Precision: 0.938, ROC-AUC: 0.989, PR-AUC: 0.938, Precision: 0.754, Recall: 0.935, MCC: 0.835, F1: 0.835\n",
      "Fold 5 - Optimal Threshold: 0.180, Avg Precision: 0.918, ROC-AUC: 0.984, PR-AUC: 0.918, Precision: 0.505, Recall: 0.953, MCC: 0.685, F1: 0.660\n",
      "Evaluating ANN...\n",
      "Fold 1 - Optimal Threshold: 0.087, Avg Precision: 0.594, ROC-AUC: 0.816, PR-AUC: 0.594, Precision: 0.441, Recall: 0.583, MCC: 0.493, F1: 0.502\n",
      "Fold 2 - Optimal Threshold: 0.058, Avg Precision: 0.526, ROC-AUC: 0.856, PR-AUC: 0.525, Precision: 0.390, Recall: 0.593, MCC: 0.466, F1: 0.471\n",
      "Fold 3 - Optimal Threshold: 0.031, Avg Precision: 0.558, ROC-AUC: 0.824, PR-AUC: 0.557, Precision: 0.089, Recall: 0.713, MCC: 0.208, F1: 0.158\n",
      "Fold 4 - Optimal Threshold: 0.028, Avg Precision: 0.466, ROC-AUC: 0.819, PR-AUC: 0.465, Precision: 0.089, Recall: 0.722, MCC: 0.209, F1: 0.158\n",
      "Fold 5 - Optimal Threshold: 0.035, Avg Precision: 0.529, ROC-AUC: 0.835, PR-AUC: 0.529, Precision: 0.136, Recall: 0.654, MCC: 0.265, F1: 0.225\n",
      "\n",
      "Random Forest:\n",
      "Mean Optimal Threshold: 0.029, Std Dev: 0.002\n",
      "Mean Average Precision: 0.771, Std Dev: 0.063\n",
      "Mean ROC-AUC: 0.940, Std Dev: 0.034\n",
      "Mean PR-AUC: 0.770, Std Dev: 0.063\n",
      "Mean Precision: 0.246, Std Dev: 0.062\n",
      "Mean Recall: 0.855, Std Dev: 0.052\n",
      "Mean MCC: 0.433, Std Dev: 0.071\n",
      "Mean F1 Score: 0.378, Std Dev: 0.079\n",
      "\n",
      "XGBoost:\n",
      "Mean Optimal Threshold: 0.179, Std Dev: 0.017\n",
      "Mean Average Precision: 0.935, Std Dev: 0.019\n",
      "Mean ROC-AUC: 0.983, Std Dev: 0.011\n",
      "Mean PR-AUC: 0.935, Std Dev: 0.019\n",
      "Mean Precision: 0.662, Std Dev: 0.104\n",
      "Mean Recall: 0.946, Std Dev: 0.020\n",
      "Mean MCC: 0.783, Std Dev: 0.061\n",
      "Mean F1 Score: 0.774, Std Dev: 0.070\n",
      "\n",
      "ANN:\n",
      "Mean Optimal Threshold: 0.048, Std Dev: 0.022\n",
      "Mean Average Precision: 0.535, Std Dev: 0.042\n",
      "Mean ROC-AUC: 0.830, Std Dev: 0.015\n",
      "Mean PR-AUC: 0.534, Std Dev: 0.042\n",
      "Mean Precision: 0.229, Std Dev: 0.154\n",
      "Mean Recall: 0.653, Std Dev: 0.058\n",
      "Mean MCC: 0.328, Std Dev: 0.126\n",
      "Mean F1 Score: 0.303, Std Dev: 0.152\n",
      "\n",
      "Mean Metrics for Each Model (rounded to three decimal places):\n",
      "\n",
      "Random Forest:\n",
      "Mean Optimal Threshold: 0.029, Std Dev: 0.002\n",
      "Mean Average Precision: 0.771, Std Dev: 0.063\n",
      "Mean ROC-AUC: 0.94, Std Dev: 0.034\n",
      "Mean PR-AUC: 0.77, Std Dev: 0.063\n",
      "Mean Precision: 0.246, Std Dev: 0.062\n",
      "Mean Recall: 0.855, Std Dev: 0.052\n",
      "Mean MCC: 0.433, Std Dev: 0.071\n",
      "Mean F1 Score: 0.378, Std Dev: 0.079\n",
      "\n",
      "XGBoost:\n",
      "Mean Optimal Threshold: 0.17900000512599945, Std Dev: 0.017\n",
      "Mean Average Precision: 0.935, Std Dev: 0.019\n",
      "Mean ROC-AUC: 0.983, Std Dev: 0.011\n",
      "Mean PR-AUC: 0.935, Std Dev: 0.019\n",
      "Mean Precision: 0.662, Std Dev: 0.104\n",
      "Mean Recall: 0.946, Std Dev: 0.020\n",
      "Mean MCC: 0.783, Std Dev: 0.061\n",
      "Mean F1 Score: 0.774, Std Dev: 0.070\n",
      "\n",
      "ANN:\n",
      "Mean Optimal Threshold: 0.048, Std Dev: 0.022\n",
      "Mean Average Precision: 0.535, Std Dev: 0.042\n",
      "Mean ROC-AUC: 0.83, Std Dev: 0.015\n",
      "Mean PR-AUC: 0.534, Std Dev: 0.042\n",
      "Mean Precision: 0.229, Std Dev: 0.154\n",
      "Mean Recall: 0.653, Std Dev: 0.058\n",
      "Mean MCC: 0.328, Std Dev: 0.126\n",
      "Mean F1 Score: 0.303, Std Dev: 0.152\n",
      "\n",
      "Mean Metric Scores for Each Model:\n",
      "Optimal Threshold: [0.029, 0.179, 0.048]\n",
      "Average Precision: [0.771, 0.935, 0.535]\n",
      "ROC-AUC: [0.94, 0.983, 0.83]\n",
      "PR-AUC: [0.77, 0.935, 0.534]\n",
      "Precision: [0.246, 0.662, 0.229]\n",
      "Recall: [0.855, 0.946, 0.653]\n",
      "MCC: [0.433, 0.783, 0.328]\n",
      "F1 Score: [0.378, 0.774, 0.303]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score, precision_score,\n",
    "    recall_score, matthews_corrcoef, roc_curve, precision_recall_curve,\n",
    "    f1_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred_prob):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    return thresholds[optimal_idx]\n",
    "\n",
    "# Initialize the StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Define the models in a dictionary\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=8, n_estimators=270, n_jobs=40),\n",
    "    'XGBoost': XGBClassifier(learning_rate=0.01, max_depth=7, colsample_bytree=0.73, gamma=1.96, min_child_weight=8, subsample=0.71, n_estimators=150),\n",
    "    'ANN': MLPClassifier(hidden_layer_sizes=(50,), activation='tanh', alpha=0.0070, learning_rate='invscaling', solver='sgd')\n",
    "}\n",
    "\n",
    "# Perform stratified 5-fold cross-validation for each model\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    metrics = {\n",
    "        'Optimal Threshold': [],\n",
    "        'Average Precision': [],\n",
    "        'ROC-AUC': [],\n",
    "        'PR-AUC': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'MCC': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in skf.split(X_grid_train, y_grid_train):\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_test = X_grid_train.iloc[train_index], X_grid_train.iloc[test_index]\n",
    "        y_train, y_test = y_grid_train[train_index], y_grid_train[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities on the validation set\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_optimal_threshold(y_test, y_pred_prob)\n",
    "        \n",
    "        # Make predictions using the optimal threshold\n",
    "        y_pred = (y_pred_prob >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_precision = average_precision_score(y_test, y_pred_prob)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Calculate PR-AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "        \n",
    "        # Store metrics\n",
    "        metrics['Optimal Threshold'].append(optimal_threshold)\n",
    "        metrics['Average Precision'].append(avg_precision)\n",
    "        metrics['ROC-AUC'].append(roc_auc)\n",
    "        metrics['PR-AUC'].append(pr_auc)\n",
    "        metrics['Precision'].append(precision)\n",
    "        metrics['Recall'].append(recall)\n",
    "        metrics['MCC'].append(mcc)\n",
    "        metrics['F1 Score'].append(f1)\n",
    "        \n",
    "        print(f\"Fold {fold} - Optimal Threshold: {optimal_threshold:.3f}, Avg Precision: {avg_precision:.3f}, ROC-AUC: {roc_auc:.3f}, PR-AUC: {pr_auc:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, MCC: {mcc:.3f}, F1: {f1:.3f}\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate mean and standard deviation of each metric\n",
    "    results[model_name] = {metric: (np.mean(values), np.std(values)) for metric, values in metrics.items()}\n",
    "\n",
    "# Print overall results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        print(f\"Mean {metric}: {mean:.3f}, Std Dev: {std:.3f}\")\n",
    "\n",
    "# Print mean metrics for each model\n",
    "print(\"\\nMean Metrics for Each Model (rounded to three decimal places):\")\n",
    "mean_metrics = {metric: [] for metric in metrics.keys()}\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        mean_rounded = round(mean, 3)\n",
    "        mean_metrics[metric].append(mean_rounded)\n",
    "        print(f\"Mean {metric}: {mean_rounded}, Std Dev: {std:.3f}\")\n",
    "\n",
    "print(\"\\nMean Metric Scores for Each Model:\")\n",
    "for metric, scores in mean_metrics.items():\n",
    "    print(f\"{metric}: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ab555-43c0-462a-88ad-7fb8f03db6ef",
   "metadata": {},
   "source": [
    "# **Cross validation with DeepCoy decoys in the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21708b-6dca-499d-8c79-4e9656dad066",
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_train = pd.concat([plec_train_true_actives,plec_train_deepcoys_decoys])\n",
    "grid_train = pd.concat([grid_train_true_actives,grid_train_deepcoys_decoys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa5561fa-af4f-49aa-a140-39f4646d7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X_plec_train, y_plec_train = plec_train.drop(['class', 'potency','index'], axis= 1), plec_train['class']\n",
    "X_grid_train, y_grid_train = grid_train.drop(['class', 'potency','index'], axis= 1), grid_train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a36474d-26a0-42e6-812b-f386ff03e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_train_reset = plec_train.reset_index(drop=True)\n",
    "grid_train_reset = grid_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "86c15abd-33d0-4d5e-8941-16dc64ee7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plec_train, y_plec_train = plec_train_reset.drop(['class', 'potency','index'], axis= 1), plec_train_reset['class']\n",
    "X_grid_train, y_grid_train = grid_train_reset.drop(['class', 'potency','index'], axis= 1), grid_train_reset['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "26f15fd8-17ab-481e-815c-14056f6b4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_plec_train = y_plec_train.map({'active': 1, 'inactive': 0})\n",
    "y_grid_train = y_grid_train.map({'active': 1, 'inactive': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f753619a-bbed-4651-a635-fea5b3424f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRID_0</th>\n",
       "      <th>GRID_1</th>\n",
       "      <th>GRID_2</th>\n",
       "      <th>GRID_3</th>\n",
       "      <th>GRID_4</th>\n",
       "      <th>GRID_5</th>\n",
       "      <th>GRID_6</th>\n",
       "      <th>GRID_7</th>\n",
       "      <th>GRID_8</th>\n",
       "      <th>GRID_9</th>\n",
       "      <th>...</th>\n",
       "      <th>GRID_2042</th>\n",
       "      <th>GRID_2043</th>\n",
       "      <th>GRID_2044</th>\n",
       "      <th>GRID_2045</th>\n",
       "      <th>GRID_2046</th>\n",
       "      <th>GRID_2047</th>\n",
       "      <th>GRID_2048</th>\n",
       "      <th>GRID_2049</th>\n",
       "      <th>GRID_2050</th>\n",
       "      <th>GRID_2051</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22684</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22685</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22686</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22689 rows × 2052 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GRID_0  GRID_1  GRID_2  GRID_3  GRID_4  GRID_5  GRID_6  GRID_7  GRID_8  \\\n",
       "0           0       1       0       1       1       0       0       0       0   \n",
       "1           0       0       0       0       1       0       0       1       0   \n",
       "2           0       0       0       0       1       0       0       1       0   \n",
       "3           0       0       0       0       1       0       0       1       0   \n",
       "4           0       0       0       0       1       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "22684       0       0       0       0       0       0       0       1       0   \n",
       "22685       0       0       0       0       0       0       0       0       0   \n",
       "22686       0       0       0       0       1       0       0       0       0   \n",
       "22687       0       0       0       0       1       0       0       0       0   \n",
       "22688       0       0       0       0       1       0       0       0       0   \n",
       "\n",
       "       GRID_9  ...  GRID_2042  GRID_2043  GRID_2044  GRID_2045  GRID_2046  \\\n",
       "0           0  ...          0          0          2          8          0   \n",
       "1           0  ...          2         16          0          0          0   \n",
       "2           0  ...          0         10          0          0          2   \n",
       "3           0  ...          0          6          2          4          0   \n",
       "4           0  ...          0          2          0          0          0   \n",
       "...       ...  ...        ...        ...        ...        ...        ...   \n",
       "22684       0  ...          0          0          0          0          0   \n",
       "22685       0  ...          0          0          0          0          0   \n",
       "22686       0  ...          0          0          0          2          0   \n",
       "22687       0  ...          0          0          4          0          4   \n",
       "22688       0  ...          0          0          0          0          0   \n",
       "\n",
       "       GRID_2047  GRID_2048  GRID_2049  GRID_2050  GRID_2051  \n",
       "0              0          0          0          0          0  \n",
       "1              0          0          0          0          0  \n",
       "2              4          0          0          2          0  \n",
       "3              0          0          1          0          0  \n",
       "4              0          0          4          0          0  \n",
       "...          ...        ...        ...        ...        ...  \n",
       "22684          0          0          0          2          0  \n",
       "22685          0          0          2          2          0  \n",
       "22686          0          0          2          0          0  \n",
       "22687          0          0          0          0          0  \n",
       "22688          0          0          0          0          0  \n",
       "\n",
       "[22689 rows x 2052 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_grid_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49369d4d-2ecb-4ebe-b11e-f1ca7d26f861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest...\n",
      "Fold 1 - Optimal Threshold: 0.030, Avg Precision: 0.907, ROC-AUC: 0.997, PR-AUC: 0.907, Precision: 0.566, Recall: 0.991, MCC: 0.742, F1: 0.721\n",
      "Fold 2 - Optimal Threshold: 0.035, Avg Precision: 0.952, ROC-AUC: 0.998, PR-AUC: 0.952, Precision: 0.682, Recall: 0.991, MCC: 0.817, F1: 0.808\n",
      "Fold 3 - Optimal Threshold: 0.032, Avg Precision: 0.884, ROC-AUC: 0.996, PR-AUC: 0.883, Precision: 0.482, Recall: 0.981, MCC: 0.678, F1: 0.646\n",
      "Fold 4 - Optimal Threshold: 0.029, Avg Precision: 0.870, ROC-AUC: 0.996, PR-AUC: 0.870, Precision: 0.461, Recall: 0.991, MCC: 0.666, F1: 0.629\n",
      "Fold 5 - Optimal Threshold: 0.030, Avg Precision: 0.929, ROC-AUC: 0.998, PR-AUC: 0.928, Precision: 0.473, Recall: 1.000, MCC: 0.679, F1: 0.643\n",
      "Evaluating XGBoost...\n",
      "Fold 1 - Optimal Threshold: 0.139, Avg Precision: 0.964, ROC-AUC: 0.999, PR-AUC: 0.964, Precision: 0.470, Recall: 1.000, MCC: 0.676, F1: 0.639\n",
      "Fold 2 - Optimal Threshold: 0.207, Avg Precision: 0.988, ROC-AUC: 0.999, PR-AUC: 0.988, Precision: 0.815, Recall: 0.981, MCC: 0.892, F1: 0.891\n",
      "Fold 3 - Optimal Threshold: 0.135, Avg Precision: 0.944, ROC-AUC: 0.998, PR-AUC: 0.944, Precision: 0.384, Recall: 1.000, MCC: 0.608, F1: 0.555\n",
      "Fold 4 - Optimal Threshold: 0.169, Avg Precision: 0.929, ROC-AUC: 0.996, PR-AUC: 0.929, Precision: 0.686, Recall: 0.972, MCC: 0.812, F1: 0.805\n",
      "Fold 5 - Optimal Threshold: 0.154, Avg Precision: 0.966, ROC-AUC: 0.999, PR-AUC: 0.966, Precision: 0.550, Recall: 0.981, MCC: 0.727, F1: 0.705\n",
      "Evaluating ANN...\n",
      "Fold 1 - Optimal Threshold: 0.044, Avg Precision: 0.678, ROC-AUC: 0.950, PR-AUC: 0.678, Precision: 0.155, Recall: 0.889, MCC: 0.342, F1: 0.264\n",
      "Fold 2 - Optimal Threshold: 0.034, Avg Precision: 0.664, ROC-AUC: 0.929, PR-AUC: 0.664, Precision: 0.108, Recall: 0.870, MCC: 0.269, F1: 0.192\n",
      "Fold 3 - Optimal Threshold: 0.085, Avg Precision: 0.688, ROC-AUC: 0.958, PR-AUC: 0.686, Precision: 0.263, Recall: 0.852, MCC: 0.453, F1: 0.402\n",
      "Fold 4 - Optimal Threshold: 0.065, Avg Precision: 0.490, ROC-AUC: 0.958, PR-AUC: 0.487, Precision: 0.178, Recall: 0.889, MCC: 0.371, F1: 0.296\n",
      "Fold 5 - Optimal Threshold: 0.035, Avg Precision: 0.582, ROC-AUC: 0.932, PR-AUC: 0.581, Precision: 0.105, Recall: 0.897, MCC: 0.269, F1: 0.187\n",
      "\n",
      "Random Forest:\n",
      "Mean Optimal Threshold: 0.031, Std Dev: 0.002\n",
      "Mean Average Precision: 0.908, Std Dev: 0.030\n",
      "Mean ROC-AUC: 0.997, Std Dev: 0.001\n",
      "Mean PR-AUC: 0.908, Std Dev: 0.030\n",
      "Mean Precision: 0.533, Std Dev: 0.083\n",
      "Mean Recall: 0.991, Std Dev: 0.006\n",
      "Mean MCC: 0.716, Std Dev: 0.057\n",
      "Mean F1 Score: 0.689, Std Dev: 0.067\n",
      "\n",
      "XGBoost:\n",
      "Mean Optimal Threshold: 0.161, Std Dev: 0.026\n",
      "Mean Average Precision: 0.958, Std Dev: 0.020\n",
      "Mean ROC-AUC: 0.998, Std Dev: 0.001\n",
      "Mean PR-AUC: 0.958, Std Dev: 0.020\n",
      "Mean Precision: 0.581, Std Dev: 0.154\n",
      "Mean Recall: 0.987, Std Dev: 0.011\n",
      "Mean MCC: 0.743, Std Dev: 0.100\n",
      "Mean F1 Score: 0.719, Std Dev: 0.119\n",
      "\n",
      "ANN:\n",
      "Mean Optimal Threshold: 0.053, Std Dev: 0.020\n",
      "Mean Average Precision: 0.621, Std Dev: 0.075\n",
      "Mean ROC-AUC: 0.945, Std Dev: 0.013\n",
      "Mean PR-AUC: 0.619, Std Dev: 0.076\n",
      "Mean Precision: 0.162, Std Dev: 0.058\n",
      "Mean Recall: 0.879, Std Dev: 0.016\n",
      "Mean MCC: 0.341, Std Dev: 0.069\n",
      "Mean F1 Score: 0.268, Std Dev: 0.079\n",
      "\n",
      "Mean Metrics for Each Model (rounded to three decimal places):\n",
      "\n",
      "Random Forest:\n",
      "Mean Optimal Threshold: 0.031, Std Dev: 0.002\n",
      "Mean Average Precision: 0.908, Std Dev: 0.030\n",
      "Mean ROC-AUC: 0.997, Std Dev: 0.001\n",
      "Mean PR-AUC: 0.908, Std Dev: 0.030\n",
      "Mean Precision: 0.533, Std Dev: 0.083\n",
      "Mean Recall: 0.991, Std Dev: 0.006\n",
      "Mean MCC: 0.716, Std Dev: 0.057\n",
      "Mean F1 Score: 0.689, Std Dev: 0.067\n",
      "\n",
      "XGBoost:\n",
      "Mean Optimal Threshold: 0.16099999845027924, Std Dev: 0.026\n",
      "Mean Average Precision: 0.958, Std Dev: 0.020\n",
      "Mean ROC-AUC: 0.998, Std Dev: 0.001\n",
      "Mean PR-AUC: 0.958, Std Dev: 0.020\n",
      "Mean Precision: 0.581, Std Dev: 0.154\n",
      "Mean Recall: 0.987, Std Dev: 0.011\n",
      "Mean MCC: 0.743, Std Dev: 0.100\n",
      "Mean F1 Score: 0.719, Std Dev: 0.119\n",
      "\n",
      "ANN:\n",
      "Mean Optimal Threshold: 0.053, Std Dev: 0.020\n",
      "Mean Average Precision: 0.621, Std Dev: 0.075\n",
      "Mean ROC-AUC: 0.945, Std Dev: 0.013\n",
      "Mean PR-AUC: 0.619, Std Dev: 0.076\n",
      "Mean Precision: 0.162, Std Dev: 0.058\n",
      "Mean Recall: 0.879, Std Dev: 0.016\n",
      "Mean MCC: 0.341, Std Dev: 0.069\n",
      "Mean F1 Score: 0.268, Std Dev: 0.079\n",
      "\n",
      "Mean Metric Scores for Each Model:\n",
      "Optimal Threshold: [0.031, 0.161, 0.053]\n",
      "Average Precision: [0.908, 0.958, 0.621]\n",
      "ROC-AUC: [0.997, 0.998, 0.945]\n",
      "PR-AUC: [0.908, 0.958, 0.619]\n",
      "Precision: [0.533, 0.581, 0.162]\n",
      "Recall: [0.991, 0.987, 0.879]\n",
      "MCC: [0.716, 0.743, 0.341]\n",
      "F1 Score: [0.689, 0.719, 0.268]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score, precision_score,\n",
    "    recall_score, matthews_corrcoef, roc_curve, precision_recall_curve,\n",
    "    f1_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred_prob):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    return thresholds[optimal_idx]\n",
    "\n",
    "# Initialize the StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Define the models in a dictionary\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=8, n_estimators=270, n_jobs=40),\n",
    "    'XGBoost': XGBClassifier(learning_rate=0.01, max_depth=7, colsample_bytree=0.73, gamma=1.96, min_child_weight=8, subsample=0.71, n_estimators=150),\n",
    "    'ANN': MLPClassifier(hidden_layer_sizes=(50,), activation='tanh', alpha=0.0070, learning_rate='invscaling', solver='sgd')\n",
    "}\n",
    "\n",
    "# Perform stratified 5-fold cross-validation for each model\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    metrics = {\n",
    "        'Optimal Threshold': [],\n",
    "        'Average Precision': [],\n",
    "        'ROC-AUC': [],\n",
    "        'PR-AUC': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'MCC': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in skf.split(X_plec_train, y_plec_train):\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_test = X_plec_train.iloc[train_index], X_plec_train.iloc[test_index]\n",
    "        y_train, y_test = y_plec_train[train_index], y_plec_train[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities on the validation set\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_optimal_threshold(y_test, y_pred_prob)\n",
    "        \n",
    "        # Make predictions using the optimal threshold\n",
    "        y_pred = (y_pred_prob >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_precision = average_precision_score(y_test, y_pred_prob)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Calculate PR-AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "        \n",
    "        # Store metrics\n",
    "        metrics['Optimal Threshold'].append(optimal_threshold)\n",
    "        metrics['Average Precision'].append(avg_precision)\n",
    "        metrics['ROC-AUC'].append(roc_auc)\n",
    "        metrics['PR-AUC'].append(pr_auc)\n",
    "        metrics['Precision'].append(precision)\n",
    "        metrics['Recall'].append(recall)\n",
    "        metrics['MCC'].append(mcc)\n",
    "        metrics['F1 Score'].append(f1)\n",
    "        \n",
    "        print(f\"Fold {fold} - Optimal Threshold: {optimal_threshold:.3f}, Avg Precision: {avg_precision:.3f}, ROC-AUC: {roc_auc:.3f}, PR-AUC: {pr_auc:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, MCC: {mcc:.3f}, F1: {f1:.3f}\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate mean and standard deviation of each metric\n",
    "    results[model_name] = {metric: (np.mean(values), np.std(values)) for metric, values in metrics.items()}\n",
    "\n",
    "# Print overall results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        print(f\"Mean {metric}: {mean:.3f}, Std Dev: {std:.3f}\")\n",
    "\n",
    "# Print mean metrics for each model\n",
    "print(\"\\nMean Metrics for Each Model (rounded to three decimal places):\")\n",
    "mean_metrics = {metric: [] for metric in metrics.keys()}\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        mean_rounded = round(mean, 3)\n",
    "        mean_metrics[metric].append(mean_rounded)\n",
    "        print(f\"Mean {metric}: {mean_rounded}, Std Dev: {std:.3f}\")\n",
    "\n",
    "print(\"\\nMean Metric Scores for Each Model:\")\n",
    "for metric, scores in mean_metrics.items():\n",
    "    print(f\"{metric}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8a4a9c3a-7950-4692-9431-a1a6034975b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Random Forest...\n",
      "Fold 1 - Optimal Threshold: 0.042, Avg Precision: 0.943, ROC-AUC: 0.995, PR-AUC: 0.943, Precision: 0.658, Recall: 0.963, MCC: 0.791, F1: 0.782\n",
      "Fold 2 - Optimal Threshold: 0.051, Avg Precision: 0.982, ROC-AUC: 1.000, PR-AUC: 0.982, Precision: 0.794, Recall: 1.000, MCC: 0.888, F1: 0.885\n",
      "Fold 3 - Optimal Threshold: 0.034, Avg Precision: 0.918, ROC-AUC: 0.994, PR-AUC: 0.918, Precision: 0.405, Recall: 0.972, MCC: 0.616, F1: 0.572\n",
      "Fold 4 - Optimal Threshold: 0.039, Avg Precision: 0.907, ROC-AUC: 0.995, PR-AUC: 0.907, Precision: 0.484, Recall: 0.954, MCC: 0.669, F1: 0.642\n",
      "Fold 5 - Optimal Threshold: 0.034, Avg Precision: 0.921, ROC-AUC: 0.995, PR-AUC: 0.921, Precision: 0.387, Recall: 0.972, MCC: 0.601, F1: 0.553\n",
      "Evaluating XGBoost...\n",
      "Fold 1 - Optimal Threshold: 0.190, Avg Precision: 0.974, ROC-AUC: 0.993, PR-AUC: 0.974, Precision: 0.847, Recall: 0.972, MCC: 0.905, F1: 0.905\n",
      "Fold 2 - Optimal Threshold: 0.188, Avg Precision: 0.985, ROC-AUC: 0.999, PR-AUC: 0.985, Precision: 0.817, Recall: 0.991, MCC: 0.897, F1: 0.895\n",
      "Fold 3 - Optimal Threshold: 0.146, Avg Precision: 0.952, ROC-AUC: 0.996, PR-AUC: 0.952, Precision: 0.549, Recall: 0.981, MCC: 0.727, F1: 0.704\n",
      "Fold 4 - Optimal Threshold: 0.177, Avg Precision: 0.954, ROC-AUC: 0.996, PR-AUC: 0.954, Precision: 0.686, Recall: 0.972, MCC: 0.812, F1: 0.805\n",
      "Fold 5 - Optimal Threshold: 0.174, Avg Precision: 0.968, ROC-AUC: 0.996, PR-AUC: 0.968, Precision: 0.750, Recall: 0.981, MCC: 0.854, F1: 0.850\n",
      "Evaluating ANN...\n",
      "Fold 1 - Optimal Threshold: 0.047, Avg Precision: 0.696, ROC-AUC: 0.945, PR-AUC: 0.696, Precision: 0.190, Recall: 0.833, MCC: 0.372, F1: 0.309\n",
      "Fold 2 - Optimal Threshold: 0.050, Avg Precision: 0.749, ROC-AUC: 0.937, PR-AUC: 0.749, Precision: 0.238, Recall: 0.852, MCC: 0.429, F1: 0.372\n",
      "Fold 3 - Optimal Threshold: 0.032, Avg Precision: 0.617, ROC-AUC: 0.925, PR-AUC: 0.616, Precision: 0.126, Recall: 0.843, MCC: 0.292, F1: 0.220\n",
      "Fold 4 - Optimal Threshold: 0.053, Avg Precision: 0.699, ROC-AUC: 0.934, PR-AUC: 0.698, Precision: 0.289, Recall: 0.815, MCC: 0.466, F1: 0.426\n",
      "Fold 5 - Optimal Threshold: 0.035, Avg Precision: 0.538, ROC-AUC: 0.898, PR-AUC: 0.537, Precision: 0.112, Recall: 0.813, MCC: 0.265, F1: 0.198\n",
      "\n",
      "Random Forest:\n",
      "Mean Optimal Threshold: 0.040, Std Dev: 0.006\n",
      "Mean Average Precision: 0.934, Std Dev: 0.026\n",
      "Mean ROC-AUC: 0.996, Std Dev: 0.002\n",
      "Mean PR-AUC: 0.934, Std Dev: 0.026\n",
      "Mean Precision: 0.546, Std Dev: 0.157\n",
      "Mean Recall: 0.972, Std Dev: 0.015\n",
      "Mean MCC: 0.713, Std Dev: 0.110\n",
      "Mean F1 Score: 0.687, Std Dev: 0.128\n",
      "\n",
      "XGBoost:\n",
      "Mean Optimal Threshold: 0.175, Std Dev: 0.016\n",
      "Mean Average Precision: 0.966, Std Dev: 0.012\n",
      "Mean ROC-AUC: 0.996, Std Dev: 0.002\n",
      "Mean PR-AUC: 0.966, Std Dev: 0.013\n",
      "Mean Precision: 0.730, Std Dev: 0.106\n",
      "Mean Recall: 0.980, Std Dev: 0.007\n",
      "Mean MCC: 0.839, Std Dev: 0.065\n",
      "Mean F1 Score: 0.832, Std Dev: 0.073\n",
      "\n",
      "ANN:\n",
      "Mean Optimal Threshold: 0.043, Std Dev: 0.008\n",
      "Mean Average Precision: 0.660, Std Dev: 0.074\n",
      "Mean ROC-AUC: 0.928, Std Dev: 0.016\n",
      "Mean PR-AUC: 0.659, Std Dev: 0.074\n",
      "Mean Precision: 0.191, Std Dev: 0.067\n",
      "Mean Recall: 0.831, Std Dev: 0.015\n",
      "Mean MCC: 0.365, Std Dev: 0.077\n",
      "Mean F1 Score: 0.305, Std Dev: 0.087\n",
      "\n",
      "Mean Metrics for Each Model (rounded to three decimal places):\n",
      "\n",
      "Random Forest:\n",
      "Mean Optimal Threshold: 0.04, Std Dev: 0.006\n",
      "Mean Average Precision: 0.934, Std Dev: 0.026\n",
      "Mean ROC-AUC: 0.996, Std Dev: 0.002\n",
      "Mean PR-AUC: 0.934, Std Dev: 0.026\n",
      "Mean Precision: 0.546, Std Dev: 0.157\n",
      "Mean Recall: 0.972, Std Dev: 0.015\n",
      "Mean MCC: 0.713, Std Dev: 0.110\n",
      "Mean F1 Score: 0.687, Std Dev: 0.128\n",
      "\n",
      "XGBoost:\n",
      "Mean Optimal Threshold: 0.17499999701976776, Std Dev: 0.016\n",
      "Mean Average Precision: 0.966, Std Dev: 0.012\n",
      "Mean ROC-AUC: 0.996, Std Dev: 0.002\n",
      "Mean PR-AUC: 0.966, Std Dev: 0.013\n",
      "Mean Precision: 0.73, Std Dev: 0.106\n",
      "Mean Recall: 0.98, Std Dev: 0.007\n",
      "Mean MCC: 0.839, Std Dev: 0.065\n",
      "Mean F1 Score: 0.832, Std Dev: 0.073\n",
      "\n",
      "ANN:\n",
      "Mean Optimal Threshold: 0.043, Std Dev: 0.008\n",
      "Mean Average Precision: 0.66, Std Dev: 0.074\n",
      "Mean ROC-AUC: 0.928, Std Dev: 0.016\n",
      "Mean PR-AUC: 0.659, Std Dev: 0.074\n",
      "Mean Precision: 0.191, Std Dev: 0.067\n",
      "Mean Recall: 0.831, Std Dev: 0.015\n",
      "Mean MCC: 0.365, Std Dev: 0.077\n",
      "Mean F1 Score: 0.305, Std Dev: 0.087\n",
      "\n",
      "Mean Metric Scores for Each Model:\n",
      "Optimal Threshold: [0.04, 0.175, 0.043]\n",
      "Average Precision: [0.934, 0.966, 0.66]\n",
      "ROC-AUC: [0.996, 0.996, 0.928]\n",
      "PR-AUC: [0.934, 0.966, 0.659]\n",
      "Precision: [0.546, 0.73, 0.191]\n",
      "Recall: [0.972, 0.98, 0.831]\n",
      "MCC: [0.713, 0.839, 0.365]\n",
      "F1 Score: [0.687, 0.832, 0.305]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score, precision_score,\n",
    "    recall_score, matthews_corrcoef, roc_curve, precision_recall_curve,\n",
    "    f1_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred_prob):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    return thresholds[optimal_idx]\n",
    "\n",
    "# Initialize the StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Define the models in a dictionary\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(max_depth=3, max_features='log2', min_samples_leaf=1, min_samples_split=8, n_estimators=270, n_jobs=40),\n",
    "    'XGBoost': XGBClassifier(learning_rate=0.01, max_depth=7, colsample_bytree=0.73, gamma=1.96, min_child_weight=8, subsample=0.71, n_estimators=150),\n",
    "    'ANN': MLPClassifier(hidden_layer_sizes=(50,), activation='tanh', alpha=0.0070, learning_rate='invscaling', solver='sgd')\n",
    "}\n",
    "\n",
    "# Perform stratified 5-fold cross-validation for each model\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    metrics = {\n",
    "        'Optimal Threshold': [],\n",
    "        'Average Precision': [],\n",
    "        'ROC-AUC': [],\n",
    "        'PR-AUC': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'MCC': [],\n",
    "        'F1 Score': []\n",
    "    }\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in skf.split(X_grid_train, y_grid_train):\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_test = X_grid_train.iloc[train_index], X_grid_train.iloc[test_index]\n",
    "        y_train, y_test = y_grid_train[train_index], y_grid_train[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities on the validation set\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold = find_optimal_threshold(y_test, y_pred_prob)\n",
    "        \n",
    "        # Make predictions using the optimal threshold\n",
    "        y_pred = (y_pred_prob >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_precision = average_precision_score(y_test, y_pred_prob)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Calculate PR-AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "        \n",
    "        # Store metrics\n",
    "        metrics['Optimal Threshold'].append(optimal_threshold)\n",
    "        metrics['Average Precision'].append(avg_precision)\n",
    "        metrics['ROC-AUC'].append(roc_auc)\n",
    "        metrics['PR-AUC'].append(pr_auc)\n",
    "        metrics['Precision'].append(precision)\n",
    "        metrics['Recall'].append(recall)\n",
    "        metrics['MCC'].append(mcc)\n",
    "        metrics['F1 Score'].append(f1)\n",
    "        \n",
    "        print(f\"Fold {fold} - Optimal Threshold: {optimal_threshold:.3f}, Avg Precision: {avg_precision:.3f}, ROC-AUC: {roc_auc:.3f}, PR-AUC: {pr_auc:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, MCC: {mcc:.3f}, F1: {f1:.3f}\")\n",
    "        fold += 1\n",
    "    \n",
    "    # Calculate mean and standard deviation of each metric\n",
    "    results[model_name] = {metric: (np.mean(values), np.std(values)) for metric, values in metrics.items()}\n",
    "\n",
    "# Print overall results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        print(f\"Mean {metric}: {mean:.3f}, Std Dev: {std:.3f}\")\n",
    "\n",
    "# Print mean metrics for each model\n",
    "print(\"\\nMean Metrics for Each Model (rounded to three decimal places):\")\n",
    "mean_metrics = {metric: [] for metric in metrics.keys()}\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        mean_rounded = round(mean, 3)\n",
    "        mean_metrics[metric].append(mean_rounded)\n",
    "        print(f\"Mean {metric}: {mean_rounded}, Std Dev: {std:.3f}\")\n",
    "\n",
    "print(\"\\nMean Metric Scores for Each Model:\")\n",
    "for metric, scores in mean_metrics.items():\n",
    "    print(f\"{metric}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa2643-25fd-4310-9fd0-92047e9463a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
