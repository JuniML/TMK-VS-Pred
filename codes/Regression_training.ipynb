{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd75b478-adbf-4075-bd15-8255399619df",
   "metadata": {},
   "source": [
    "# **Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7283a8-f579-408f-a476-9b353bb6a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import oddt\n",
    "from oddt.fingerprints import PLEC\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import matthews_corrcoef, precision_recall_curve, accuracy_score, auc\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import parallel_backend\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import deepchem as dc\n",
    "from deepchem.utils import download_url, load_from_disk\n",
    "from deepchem.utils.vina_utils import prepare_inputs\n",
    "from deepchem.models import AtomicConvModel\n",
    "from deepchem.feat import RdkitGridFeaturizer\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e923b2-e156-4708-8e1d-65fc4bb68735",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d21fdd-7669-42f7-8a23-9db65da43f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set true actives\n",
    "plec_train_true_actives = pd.read_csv('Path_to_csv')\n",
    "grid_train_true_actives = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "# test sets true actives\n",
    "plec_test_true_actives = pd.read_csv('Path_to_csv')\n",
    "grid_test_true_actives = pd.read_csv('Path_to_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d22ff3e-4cb7-48f8-bc53-b1e6f36a8953",
   "metadata": {},
   "source": [
    "# **Load Decoys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d95a3-63e4-47f4-9882-c75196e26d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set random_decoys\n",
    "plec_train_random_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_train_random_decoys = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "# test sets random_decoys\n",
    "plec_test_random_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_test_random_decoys = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "\n",
    "# training set deepcoy decoys\n",
    "plec_train_deepcoy_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_train_deepcoy_decoys = pd.read_csv('Path_to_csv')\n",
    "\n",
    "\n",
    "# test sets deepcoy decoys\n",
    "plec_test_deepcoy_decoys = pd.read_csv('Path_to_csv')\n",
    "grid_test_deepcoy_decoys = pd.read_csv('Path_to_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece4130-faa8-45c9-8331-b06e96918e04",
   "metadata": {},
   "source": [
    "# Generate train set with true actives and Random Decoys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb8a4d55-25b4-4f81-af3b-bbff8c585d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_train_random = pd.concat([plec_train_true_actives,plec_train_random_decoys])\n",
    "grid_train_random = pd.concat([grid_train_true_actives,grid_train_random_decoys])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ddaf67-3ab8-4738-9a01-175c7fca6396",
   "metadata": {},
   "source": [
    "# Generate test set true actives and deepcoys decoys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84f9bdc0-da48-4c91-a676-879472507c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set with deepcoys\n",
    "test_deepcoy_plec = pd.concat([plec_test_true_actives,plec_test_deepcoy_decoys])\n",
    "test_deepcoy_grid = pd.concat([grid_test_true_actives,grid_test_deepcoy_decoys])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c927f7d5-4bae-46e5-900d-1a8f631d9c13",
   "metadata": {},
   "source": [
    "# Generate test set with true actives and random decoys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "048d05ba-b5a0-4b23-b6cc-8e395221ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set with randomdecoyss\n",
    "test_randomdecoys_plec = pd.concat([plec_test_true_actives,plec_test_randomdecoys])\n",
    "test_randomdecoys_grid = pd.concat([grid_test_true_actives,grid_test_randomdecoys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a58f42a7-ad3c-4fb4-ad01-df1d37fc3b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X_plec_train, y_plec_train = plec_train_random.drop(['class', 'potency','index'], axis= 1), plec_train_random['potency']\n",
    "X_grid_train, y_grid_train = grid_train_random.drop(['class', 'potency'], axis= 1), grid_train_random['potency']\n",
    "\n",
    "\n",
    "# test set deepcoys\n",
    "X_test_deepcoy_plec, y_test_deepcoy_plec = test_deepcoy_plec.drop(['class', 'potency','index'], axis= 1), test_deepcoy_plec['potency']\n",
    "X_test_deepcoy_grid, y_test_deepcoy_grid = test_deepcoy_grid.drop(['class', 'potency'], axis= 1), test_deepcoy_grid['potency']\n",
    "\n",
    "# test set randomdecoys\n",
    "X_test_randomdecoys_plec, y_test_randomdecoys_plec = test_randomdecoys_plec.drop(['class', 'potency','index'], axis= 1), test_randomdecoys_plec['potency']\n",
    "X_test_randomdecoys_grid, y_test_randomdecoys_grid = test_randomdecoys_grid.drop(['class', 'potency','index'], axis= 1), test_randomdecoys_grid['potency']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c791cbd9-c0cb-4009-bc4c-17c7329f2c50",
   "metadata": {},
   "source": [
    "# **Training with PLEC features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e92b70-5da3-44d8-91f3-a6fce247a299",
   "metadata": {},
   "source": [
    "# **RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9bd41dd7-61ce-45c5-98a1-80e52987c6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:46<00:00,  3.34s/trial, best loss: -3.5529274704296454]\n",
      "Best hyperparameters: {'max_depth': 3.0, 'max_features': 1, 'min_samples_leaf': 1.0, 'min_samples_split': 8.0, 'n_estimators': 270.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "\n",
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(params):\n",
    "    # Create the random forest regressor with the given parameters\n",
    "    rf_plec = RandomForestRegressor(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        min_samples_split=int(params['min_samples_split']),\n",
    "        min_samples_leaf=int(params['min_samples_leaf']),\n",
    "        max_features=params['max_features'],\n",
    "        random_state=60, # Set random state for reproducibility\n",
    "        n_jobs=40     \n",
    "    )\n",
    "\n",
    "    # Perform 5-fold cross-validation and calculate mean squared error (MSE)\n",
    "    cv_scores = cross_val_score(rf_plec, X_plec_train, y_plec_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = np.mean(cv_scores)\n",
    "    \n",
    "    # Return the negative mean squared error as the loss\n",
    "    return {'loss': mean_mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 300, 10),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 20, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 10, 1),\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None])\n",
    "}\n",
    "\n",
    "# Run the optimization\n",
    "trials = Trials()\n",
    "best_params_rf_plec_reg_P1 = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  # Adjust the number of evaluations as needed\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(60) # Set random state for reproducibility\n",
    ")\n",
    "    \n",
    "# Save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_rf_plec_reg_P1.pkl\")\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_params_rf_plec_reg_P1, file)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print('Best hyperparameters:', best_params_rf_plec_reg_P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13187516-145c-4f00-a8d6-e7622fa27f5a",
   "metadata": {},
   "source": [
    "# **save the best hyperparameters found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bcf822e7-7fb8-411a-bca7-3bb7854cb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_rf_plec_reg_P1.pkl\")\n",
    "with open(file_path, 'rb') as file:\n",
    "    best_params_rf_plec_reg_P1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66362da9-0df8-4b9f-bee0-dec6d0bab66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the hyperparameter choices to the proper format\n",
    "if best_params_rf_plec_reg_P1['max_features'] == 0:\n",
    "    best_params_rf_plec_reg_P1['max_features'] = 'sqrt'\n",
    "elif best_params_rf_plec_reg_P1['max_features'] == 1:\n",
    "    best_params_rf_plec_reg_P1['max_features'] = 'log2'\n",
    "else:\n",
    "    best_params_rf_plec_reg_P1['max_features'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51e53c-9831-4c8a-b480-c83ca603e1e4",
   "metadata": {},
   "source": [
    "# **train the RF ten times and save the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37735c41-510c-4ffd-a9a5-bbb66d97d9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5395, 0.5527, 0.5643, 0.5461, 0.5433, 0.5757, 0.5427, 0.5488, 0.5489, 0.5459]\n",
      "[0.6281, 0.6267, 0.6548, 0.6656, 0.5944, 0.6516, 0.6022, 0.6164, 0.6147, 0.5953]\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "PR_AUCs_plec_rf_P1_hard = []\n",
    "PR_AUCs_plec_rf_P2_hard = []\n",
    "for i in range(1,11):\n",
    "    rf_plec = RandomForestRegressor(\n",
    "        n_estimators=int(best_params_rf_plec_reg_P1['n_estimators']),\n",
    "        max_depth=int(best_params_rf_plec_reg_P1['max_depth']),\n",
    "        min_samples_split=int(best_params_rf_plec_reg_P1['min_samples_split']),\n",
    "        min_samples_leaf=int(best_params_rf_plec_reg_P1['min_samples_leaf']),\n",
    "        max_features=best_params_rf_plec_reg_P1['max_features'],\n",
    "        random_state=i\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    rf_plec.fit(X_plec_train, y_plec_train)\n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_rf_plec_score_P1_hard = rf_plec.predict(X_test_randomdecoys_plec_hard)\n",
    "  \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    plec_result_rf_P1_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_rf_plec_score_P1_hard,\n",
    "                                   \"Real_Score\": y_test_randomdecoys_plec_hard})\n",
    "    plec_result_rf_P1_hard['Predicted_Class'] = plec_result_rf_P1_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_rf_P1_hard['Real_Class'] = plec_result_rf_P1_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_rf_P1_hard['normalized_scores'] = (plec_result_rf_P1_hard['Predicted_Score'] - plec_result_rf_P1_hard['Predicted_Score'].min())/(plec_result_rf_P1_hard['Predicted_Score'].max() - plec_result_rf_P1_hard['Predicted_Score'].min())\n",
    "    plec_result_rf_P1_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/plec_result_rf_reg_P1_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(plec_result_rf_P1_hard['Real_Class'], plec_result_rf_P1_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_plec_rf_P1_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_rf_plec_score_P2_hard = rf_plec.predict(X_test_deepcoy_plec_hard)\n",
    " \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    plec_result_rf_P2_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_rf_plec_score_P2_hard,\n",
    "                                   \"Real_Score\": y_test_deepcoy_plec_hard})\n",
    "    plec_result_rf_P2_hard['Predicted_Class'] = plec_result_rf_P2_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_rf_P2_hard['Real_Class'] = plec_result_rf_P2_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_rf_P2_hard['normalized_scores'] = (plec_result_rf_P2_hard['Predicted_Score'] - plec_result_rf_P2_hard['Predicted_Score'].min())/(plec_result_rf_P2_hard['Predicted_Score'].max() - plec_result_rf_P2_hard['Predicted_Score'].min())\n",
    "    plec_result_rf_P2_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/plec_result_rf_reg_P2_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(plec_result_rf_P2_hard['Real_Class'], plec_result_rf_P2_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_plec_rf_P2_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "print(PR_AUCs_plec_rf_P1_hard)\n",
    "print(PR_AUCs_plec_rf_P2_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb4cac-0b39-499d-b475-ed5e147edb1d",
   "metadata": {},
   "source": [
    "# **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7a8fc07d-f3ca-4557-8e6b-625e781cd047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [16:13<00:00, 19.48s/trial, best loss: -2.6320631116598494]\n",
      "Best hyperparameters: {'colsample_bytree': 0.7308229288393999, 'gamma': 1.964045543005358, 'learning_rate': 0.010393413439404125, 'max_depth': 7.0, 'min_child_weight': 8.0, 'n_estimators': 150.0, 'subsample': 0.7140723940024111}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor  \n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "\n",
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(params):\n",
    "    # Create the XGBoost classifier with the given parameters\n",
    "    xgb_plec = XGBRegressor(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        min_child_weight=int(params['min_child_weight']),\n",
    "        gamma=params['gamma'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=42,  # Set random state for reproducibility\n",
    "        n_jobs=40  # Use 40 CPU cores for XGBClassifier\n",
    "    )\n",
    "\n",
    "    # Perform 5-fold cross-validation and calculate mean squared error (MSE)\n",
    "    cv_scores = cross_val_score(xgb_plec, X_plec_train, y_plec_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = np.mean(cv_scores)\n",
    "    \n",
    "    # Return the negative mean squared error as the loss\n",
    "    return {'loss': mean_mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 300, 10),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 15, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'gamma': hp.uniform('gamma', 0, 5),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)\n",
    "}\n",
    "\n",
    "# Run the optimization\n",
    "trials = Trials()\n",
    "best_params_xgb_plec_reg_P1 = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  # Adjust the number of evaluations as needed\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(60) # Set random state for reproducibility\n",
    ")\n",
    "    \n",
    "# Save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_xgb_plec_reg_P1.pkl\")\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_params_xgb_plec_reg_P1, file)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print('Best hyperparameters:', best_params_xgb_plec_reg_P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80448596-1617-42c3-85bc-4c7c07651fd2",
   "metadata": {},
   "source": [
    "# **save the best hyperparameters found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d99154b4-99f8-4856-8640-3a81593e5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_xgb_plec_reg_P1.pkl\")\n",
    "with open(file_path, 'rb') as file:\n",
    "    best_params_xgb_plec_reg_P1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7b048-2c2e-4d2b-ba85-b0b93654c460",
   "metadata": {},
   "source": [
    "# **train the XGB ten times and save th results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d30b9ef7-8de1-426d-a77a-3b2d5743e312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7323, 0.7562, 0.7583, 0.7538, 0.7589, 0.737, 0.7603, 0.7687, 0.7526, 0.7594]\n",
      "[0.7156, 0.7211, 0.7311, 0.7187, 0.7287, 0.7221, 0.7229, 0.733, 0.709, 0.7327]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor  \n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "PR_AUCs_plec_xgb_P1_hard = []\n",
    "PR_AUCs_plec_xgb_P2_hard = []\n",
    "for i in range(1,11):\n",
    "    xgb_plec = XGBRegressor(\n",
    "        n_estimators=int(best_params_xgb_plec_reg_P1['n_estimators']),\n",
    "        max_depth=int(best_params_xgb_plec_reg_P1['max_depth']),\n",
    "        learning_rate=best_params_xgb_plec_reg_P1['learning_rate'],\n",
    "        min_child_weight=int(best_params_xgb_plec_reg_P1['min_child_weight']),\n",
    "        gamma=best_params_xgb_plec_reg_P1['gamma'],\n",
    "        subsample=best_params_xgb_plec_reg_P1['subsample'],\n",
    "        colsample_bytree=best_params_xgb_plec_reg_P1['colsample_bytree'],\n",
    "        random_state=i,\n",
    "        n_jobs=40  # Use 40 CPU cores for XGBClassifier\n",
    ")\n",
    "    \n",
    "    # Fit the model\n",
    "    xgb_plec.fit(X_plec_train, y_plec_train)\n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_xgb_plec_score_P1_hard = xgb_plec.predict(X_test_randomdecoys_plec_hard)\n",
    "  \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    plec_result_xgb_P1_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_xgb_plec_score_P1_hard,\n",
    "                                   \"Real_Score\": y_test_randomdecoys_plec_hard})\n",
    "    plec_result_xgb_P1_hard['Predicted_Class'] = plec_result_xgb_P1_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_xgb_P1_hard['Real_Class'] = plec_result_xgb_P1_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_xgb_P1_hard['normalized_scores'] = (plec_result_xgb_P1_hard['Predicted_Score'] - plec_result_xgb_P1_hard['Predicted_Score'].min())/(plec_result_xgb_P1_hard['Predicted_Score'].max() - plec_result_xgb_P1_hard['Predicted_Score'].min())\n",
    "    plec_result_xgb_P1_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/plec_result_xgb_reg_P1_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(plec_result_xgb_P1_hard['Real_Class'], plec_result_xgb_P1_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_plec_xgb_P1_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_xgb_plec_score_P2_hard = xgb_plec.predict(X_test_deepcoy_plec_hard)\n",
    " \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    plec_result_xgb_P2_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_xgb_plec_score_P2_hard,\n",
    "                                   \"Real_Score\": y_test_deepcoy_plec_hard})\n",
    "    plec_result_xgb_P2_hard['Predicted_Class'] = plec_result_xgb_P2_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_xgb_P2_hard['Real_Class'] = plec_result_xgb_P2_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_xgb_P2_hard['normalized_scores'] = (plec_result_xgb_P2_hard['Predicted_Score'] - plec_result_xgb_P2_hard['Predicted_Score'].min())/(plec_result_xgb_P2_hard['Predicted_Score'].max() - plec_result_xgb_P2_hard['Predicted_Score'].min())\n",
    "    plec_result_xgb_P2_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/plec_result_xgb_reg_P2_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(plec_result_xgb_P2_hard['Real_Class'], plec_result_xgb_P2_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_plec_xgb_P2_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "print(PR_AUCs_plec_xgb_P1_hard)\n",
    "print(PR_AUCs_plec_xgb_P2_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad7697-b8ac-479f-b909-051343cdcc6d",
   "metadata": {},
   "source": [
    "# **ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16819698-1eeb-4845-ba28-39f953a9dcec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor  \n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "\n",
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(params):\n",
    "    # Create the ANN classifier with the given parameters\n",
    "    ann_plec = MLPRegressor(\n",
    "        hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "        activation=params['activation'],\n",
    "        solver=params['solver'],\n",
    "        alpha=params['alpha'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Perform 5-fold cross-validation and calculate mean squared error (MSE)\n",
    "    cv_scores = cross_val_score(ann_plec, X_plec_train, y_plec_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = np.mean(cv_scores)\n",
    "    \n",
    "    # Return the negative mean squared error as the loss\n",
    "    return {'loss': mean_mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'hidden_layer_sizes': hp.choice('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 100)]),\n",
    "    'activation': hp.choice('activation', ['relu', 'tanh', 'logistic']),\n",
    "    'solver': hp.choice('solver', ['adam', 'sgd', 'lbfgs']),\n",
    "    'alpha': hp.loguniform('alpha', -5, -1),  # L2 penalty parameter (e.g., from 0.00001 to 0.1)\n",
    "    'learning_rate': hp.choice('learning_rate', ['constant', 'adaptive', 'invscaling'])\n",
    "}\n",
    "\n",
    "# Run the optimization\n",
    "trials = Trials()\n",
    "best_params_ann_plec_reg_P1 = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  # Adjust the number of evaluations as needed\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(60) # Set random state for reproducibility\n",
    ")\n",
    "    \n",
    "# Save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_ann_plec_reg_P1.pkl\")\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_params_ann_plec_reg_P1, file)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print('Best hyperparameters:', best_params_ann_plec_reg_P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e375ed-8e4a-441a-82dd-650214f529df",
   "metadata": {},
   "source": [
    "# **save the best hyperparameters found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "baa41945-3c0b-4e80-9860-095a1e0500af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_ann_plec_reg_P1.pkl\")\n",
    "with open(file_path, 'rb') as file:\n",
    "    best_params_ann_plec_reg_P1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7aaeeba9-3d17-45fe-a74b-a17eb8f4e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the hyperparameter choices to the proper format\n",
    "if best_params_ann_plec_reg_P1['activation'] == 0:\n",
    "    best_params_ann_plec_reg_P1['activation'] = 'relu'\n",
    "elif best_params_ann_plec_reg_P1['activation'] == 1:\n",
    "    best_params_ann_plec_reg_P1['activation'] = 'tanh'\n",
    "else:\n",
    "    best_params_ann_plec_reg_P1['activation'] = 'logistic'\n",
    "\n",
    "\n",
    "\n",
    "# Convert the hyperparameter choices to the proper format\n",
    "if best_params_ann_plec_reg_P1['learning_rate'] == 0:\n",
    "    best_params_ann_plec_reg_P1['learning_rate'] = 'constant'\n",
    "elif best_params_ann_plec_reg_P1['learning_rate'] == 1:\n",
    "    best_params_ann_plec_reg_P1['learning_rate'] = 'adaptive'\n",
    "else:\n",
    "    best_params_ann_plec_reg_P1['learning_rate'] = 'invscaling'\n",
    "\n",
    "\n",
    "# Convert the hyperparameter choices to the proper format\n",
    "if best_params_ann_plec_reg_P1['solver'] == 0:\n",
    "    best_params_ann_plec_reg_P1['solver'] = 'adam'\n",
    "elif best_params_ann_plec_reg_P1['solver'] == 1:\n",
    "    best_params_ann_plec_reg_P1['solver'] = 'sgd'\n",
    "else:\n",
    "    best_params_ann_plec_reg_P1['solver'] = 'lbfgs'\n",
    "\n",
    "\n",
    "if best_params_ann_plec_reg_P1['hidden_layer_sizes'] == 0:\n",
    "    best_params_ann_plec_reg_P1['hidden_layer_sizes'] = (50,)\n",
    "elif best_params_ann_plec_reg_P1['hidden_layer_sizes'] == 1:\n",
    "    best_params_ann_plec_reg_P1['hidden_layer_sizes'] = (100,)\n",
    "elif best_params_ann_plec_reg_P1['hidden_layer_sizes'] == 2:\n",
    "    best_params_ann_plec_reg_P1['hidden_layer_sizes'] = (50,50)\n",
    "else:\n",
    "    best_params_ann_plec_reg_P1['hidden_layer_sizes'] = (100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a5fbf3-057f-4c40-9744-6cf508906f5b",
   "metadata": {},
   "source": [
    "# **train the ANN ten times and save th results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "afdf7a05-acbf-48c7-9c3b-45e3f2d7ecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5266, 0.4528, 0.4983, 0.5, 0.4504, 0.4616, 0.4755, 0.5022, 0.5084, 0.4934]\n",
      "[0.5307, 0.4416, 0.4964, 0.5363, 0.4575, 0.4683, 0.4989, 0.5075, 0.4954, 0.5103]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor  \n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "PR_AUCs_plec_ann_P1_hard = []\n",
    "PR_AUCs_plec_ann_P2_hard = []\n",
    "for i in range(1,11):\n",
    "    ann_plec = MLPRegressor(\n",
    "    hidden_layer_sizes=best_params_ann_plec_reg_P1['hidden_layer_sizes'],\n",
    "    activation=best_params_ann_plec_reg_P1['activation'],\n",
    "    solver=best_params_ann_plec_reg_P1['solver'],\n",
    "    alpha=best_params_ann_plec_reg_P1['alpha'],\n",
    "    learning_rate=best_params_ann_plec_reg_P1['learning_rate'],\n",
    "    random_state=i)\n",
    "    \n",
    "    \n",
    "    # Fit the model\n",
    "    ann_plec.fit(X_plec_train, y_plec_train)\n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_ann_plec_score_P1_hard = ann_plec.predict(X_test_randomdecoys_plec_hard)\n",
    "  \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    plec_result_ann_P1_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_ann_plec_score_P1_hard,\n",
    "                                   \"Real_Score\": y_test_randomdecoys_plec_hard})\n",
    "    plec_result_ann_P1_hard['Predicted_Class'] = plec_result_ann_P1_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_ann_P1_hard['Real_Class'] = plec_result_ann_P1_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_ann_P1_hard['normalized_scores'] = (plec_result_ann_P1_hard['Predicted_Score'] - plec_result_ann_P1_hard['Predicted_Score'].min())/(plec_result_ann_P1_hard['Predicted_Score'].max() - plec_result_ann_P1_hard['Predicted_Score'].min())\n",
    "    plec_result_ann_P1_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/plec_result_ann_reg_P1_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(plec_result_ann_P1_hard['Real_Class'], plec_result_ann_P1_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_plec_ann_P1_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_ann_plec_score_P2_hard = ann_plec.predict(X_test_deepcoy_plec_hard)\n",
    " \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    plec_result_ann_P2_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_ann_plec_score_P2_hard,\n",
    "                                   \"Real_Score\": y_test_deepcoy_plec_hard})\n",
    "    plec_result_ann_P2_hard['Predicted_Class'] = plec_result_ann_P2_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_ann_P2_hard['Real_Class'] = plec_result_ann_P2_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    plec_result_ann_P2_hard['normalized_scores'] = (plec_result_ann_P2_hard['Predicted_Score'] - plec_result_ann_P2_hard['Predicted_Score'].min())/(plec_result_ann_P2_hard['Predicted_Score'].max() - plec_result_ann_P2_hard['Predicted_Score'].min())\n",
    "    plec_result_ann_P2_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/plec_result_ann_reg_P2_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(plec_result_ann_P2_hard['Real_Class'], plec_result_ann_P2_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_plec_ann_P2_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "\n",
    "print(PR_AUCs_plec_ann_P1_hard)\n",
    "print(PR_AUCs_plec_ann_P2_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafcd6d-f932-494a-962e-480439d62639",
   "metadata": {},
   "source": [
    "# **Training with GRID features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a2c22-9dcb-4898-b8fd-bbbfe392e2e4",
   "metadata": {},
   "source": [
    "# **RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bc3579e6-de26-4583-8bdd-b819d682bf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:33<00:00,  3.07s/trial, best loss: -3.510822879444946] \n",
      "Best hyperparameters: {'max_depth': 3.0, 'max_features': 1, 'min_samples_leaf': 1.0, 'min_samples_split': 8.0, 'n_estimators': 270.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "\n",
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(params):\n",
    "    # Create the random forest regressor with the given parameters\n",
    "    rf_grid = RandomForestRegressor(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        min_samples_split=int(params['min_samples_split']),\n",
    "        min_samples_leaf=int(params['min_samples_leaf']),\n",
    "        max_features=params['max_features'],\n",
    "        random_state=60, # Set random state for reproducibility\n",
    "        n_jobs=40     \n",
    "    )\n",
    "\n",
    "    # Perform 5-fold cross-validation and calculate mean squared error (MSE)\n",
    "    cv_scores = cross_val_score(rf_grid, X_grid_train, y_grid_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = np.mean(cv_scores)\n",
    "    \n",
    "    # Return the negative mean squared error as the loss\n",
    "    return {'loss': mean_mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 300, 10),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 20, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 10, 1),\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None])\n",
    "}\n",
    "\n",
    "# Run the optimization\n",
    "trials = Trials()\n",
    "best_params_rf_grid_reg_P1 = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  # Adjust the number of evaluations as needed\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(60) # Set random state for reproducibility\n",
    ")\n",
    "    \n",
    "# Save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_rf_grid_reg_P1.pkl\")\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_params_rf_grid_reg_P1, file)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print('Best hyperparameters:', best_params_rf_grid_reg_P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e8900-6344-41ec-91cb-916f1d347a97",
   "metadata": {},
   "source": [
    "# **save the best hyperparameters found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2969de94-0c24-4953-bc42-56b01ed084f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_rf_grid_reg_P1.pkl\")\n",
    "with open(file_path, 'rb') as file:\n",
    "    best_params_rf_grid_reg_P1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "48a10433-afa7-4bc8-9f99-fddd06ddd8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the hyperparameter choices to the proper format\n",
    "if best_params_rf_grid_reg_P1['max_features'] == 0:\n",
    "    best_params_rf_grid_reg_P1['max_features'] = 'sqrt'\n",
    "elif best_params_rf_grid_reg_P1['max_features'] == 1:\n",
    "    best_params_rf_grid_reg_P1['max_features'] = 'log2'\n",
    "else:\n",
    "    best_params_rf_grid_reg_P1['max_features'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee73505a-ff86-42a8-8661-aae67d29969e",
   "metadata": {},
   "source": [
    "# **train the RF ten times and save th results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3eb476e6-32d3-4370-8162-b86e78052423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4498, 0.4457, 0.4318, 0.4409, 0.4496, 0.4337, 0.4407, 0.4478, 0.4301, 0.4445]\n",
      "[0.4839, 0.4773, 0.4804, 0.4693, 0.5027, 0.4793, 0.5036, 0.5086, 0.4819, 0.4681]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "PR_AUCs_grid_rf_P1_hard = []\n",
    "PR_AUCs_grid_rf_P2_hard = []\n",
    "for i in range(1,11):\n",
    "    rf_grid = RandomForestRegressor(\n",
    "        n_estimators=int(best_params_rf_grid_reg_P1['n_estimators']),\n",
    "        max_depth=int(best_params_rf_grid_reg_P1['max_depth']),\n",
    "        min_samples_split=int(best_params_rf_grid_reg_P1['min_samples_split']),\n",
    "        min_samples_leaf=int(best_params_rf_grid_reg_P1['min_samples_leaf']),\n",
    "        max_features=best_params_rf_grid_reg_P1['max_features'],\n",
    "        random_state=i\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    rf_grid.fit(X_grid_train, y_grid_train)\n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_rf_grid_score_P1_hard = rf_grid.predict(X_test_randomdecoys_grid_hard)\n",
    "  \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    grid_result_rf_P1_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_rf_grid_score_P1_hard,\n",
    "                                   \"Real_Score\": y_test_randomdecoys_grid_hard})\n",
    "    grid_result_rf_P1_hard['Predicted_Class'] = grid_result_rf_P1_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_rf_P1_hard['Real_Class'] = grid_result_rf_P1_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_rf_P1_hard['normalized_scores'] = (grid_result_rf_P1_hard['Predicted_Score'] - grid_result_rf_P1_hard['Predicted_Score'].min())/(grid_result_rf_P1_hard['Predicted_Score'].max() - grid_result_rf_P1_hard['Predicted_Score'].min())\n",
    "    grid_result_rf_P1_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/grid_result_rf_reg_P1_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(grid_result_rf_P1_hard['Real_Class'], grid_result_rf_P1_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_grid_rf_P1_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_rf_grid_score_P2_hard = rf_grid.predict(X_test_deepcoy_grid_hard)\n",
    " \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    grid_result_rf_P2_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_rf_grid_score_P2_hard,\n",
    "                                   \"Real_Score\": y_test_deepcoy_grid_hard})\n",
    "    grid_result_rf_P2_hard['Predicted_Class'] = grid_result_rf_P2_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_rf_P2_hard['Real_Class'] = grid_result_rf_P2_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_rf_P2_hard['normalized_scores'] = (grid_result_rf_P2_hard['Predicted_Score'] - grid_result_rf_P2_hard['Predicted_Score'].min())/(grid_result_rf_P2_hard['Predicted_Score'].max() - grid_result_rf_P2_hard['Predicted_Score'].min())\n",
    "    grid_result_rf_P2_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/grid_result_rf_reg_P2_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(grid_result_rf_P2_hard['Real_Class'], grid_result_rf_P2_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_grid_rf_P2_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "print(PR_AUCs_grid_rf_P1_hard)\n",
    "print(PR_AUCs_grid_rf_P2_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badfcb2-c9d6-4f28-a6c8-b5d79a4b9e9e",
   "metadata": {},
   "source": [
    "# **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "495a91b4-8945-4cd2-b9ca-1b938282936e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:34<00:00,  9.10s/trial, best loss: -2.290092991419162] \n",
      "Best hyperparameters: {'colsample_bytree': 0.7151959713442447, 'gamma': 3.051560419817014, 'learning_rate': 0.03462652763929768, 'max_depth': 4.0, 'min_child_weight': 5.0, 'n_estimators': 60.0, 'subsample': 0.518783299183045}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor  \n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "\n",
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(params):\n",
    "    # Create the XGBoost classifier with the given parameters\n",
    "    xgb_grid = XGBRegressor(\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        min_child_weight=int(params['min_child_weight']),\n",
    "        gamma=params['gamma'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=42,  # Set random state for reproducibility\n",
    "        n_jobs=40  # Use 40 CPU cores for XGBClassifier\n",
    "    )\n",
    "\n",
    "    # Perform 5-fold cross-validation and calculate mean squared error (MSE)\n",
    "    cv_scores = cross_val_score(xgb_grid, X_grid_train, y_grid_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = np.mean(cv_scores)\n",
    "    \n",
    "    # Return the negative mean squared error as the loss\n",
    "    return {'loss': mean_mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 300, 10),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 15, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'gamma': hp.uniform('gamma', 0, 5),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)\n",
    "}\n",
    "\n",
    "# Run the optimization\n",
    "trials = Trials()\n",
    "best_params_xgb_grid_reg_P1 = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  # Adjust the number of evaluations as needed\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(60) # Set random state for reproducibility\n",
    ")\n",
    "    \n",
    "# Save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_xgb_grid_reg_P1.pkl\")\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_params_xgb_grid_reg_P1, file)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print('Best hyperparameters:', best_params_xgb_grid_reg_P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc12f0e-595f-43e8-94c1-c213e03324c8",
   "metadata": {},
   "source": [
    "# **save the best hyperparameters found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ae5c9594-da61-46f1-892b-6a1448b350a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_xgb_grid_reg_P1.pkl\")\n",
    "with open(file_path, 'rb') as file:\n",
    "    best_params_xgb_grid_reg_P1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a0d7d6-a2e4-472b-a7fa-a880b90d8741",
   "metadata": {},
   "source": [
    "# **train the XGB ten times and save th results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7f4942ef-a58e-41dd-8fd6-4959b5007c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6557, 0.6792, 0.6928, 0.6606, 0.663, 0.69, 0.6555, 0.6512, 0.6646, 0.7061]\n",
      "[0.6646, 0.6825, 0.6947, 0.6742, 0.6701, 0.6778, 0.6581, 0.6655, 0.6902, 0.7121]\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "PR_AUCs_grid_xgb_P1_hard = []\n",
    "PR_AUCs_grid_xgb_P2_hard = []\n",
    "for i in range(1,11):\n",
    "    xgb_grid = XGBRegressor(\n",
    "        n_estimators=int(best_params_xgb_grid_reg_P1['n_estimators']),\n",
    "        max_depth=int(best_params_xgb_grid_reg_P1['max_depth']),\n",
    "        learning_rate=best_params_xgb_grid_reg_P1['learning_rate'],\n",
    "        min_child_weight=int(best_params_xgb_grid_reg_P1['min_child_weight']),\n",
    "        gamma=best_params_xgb_grid_reg_P1['gamma'],\n",
    "        subsample=best_params_xgb_grid_reg_P1['subsample'],\n",
    "        colsample_bytree=best_params_xgb_grid_reg_P1['colsample_bytree'],\n",
    "        random_state=i,\n",
    "        n_jobs=40  # Use 40 CPU cores for XGBClassifier\n",
    ")\n",
    "    \n",
    "    # Fit the model\n",
    "    xgb_grid.fit(X_grid_train, y_grid_train)\n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_xgb_grid_score_P1_hard = xgb_grid.predict(X_test_randomdecoys_grid_hard)\n",
    "  \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    grid_result_xgb_P1_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_xgb_grid_score_P1_hard,\n",
    "                                   \"Real_Score\": y_test_randomdecoys_grid_hard})\n",
    "    grid_result_xgb_P1_hard['Predicted_Class'] = grid_result_xgb_P1_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_xgb_P1_hard['Real_Class'] = grid_result_xgb_P1_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_xgb_P1_hard['normalized_scores'] = (grid_result_xgb_P1_hard['Predicted_Score'] - grid_result_xgb_P1_hard['Predicted_Score'].min())/(grid_result_xgb_P1_hard['Predicted_Score'].max() - grid_result_xgb_P1_hard['Predicted_Score'].min())\n",
    "    grid_result_xgb_P1_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/grid_result_xgb_reg_P1_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(grid_result_xgb_P1_hard['Real_Class'], grid_result_xgb_P1_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_grid_xgb_P1_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_xgb_grid_score_P2_hard = xgb_grid.predict(X_test_deepcoy_grid_hard)\n",
    " \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    grid_result_xgb_P2_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_xgb_grid_score_P2_hard,\n",
    "                                   \"Real_Score\": y_test_deepcoy_grid_hard})\n",
    "    grid_result_xgb_P2_hard['Predicted_Class'] = grid_result_xgb_P2_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_xgb_P2_hard['Real_Class'] = grid_result_xgb_P2_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_xgb_P2_hard['normalized_scores'] = (grid_result_xgb_P2_hard['Predicted_Score'] - grid_result_xgb_P2_hard['Predicted_Score'].min())/(grid_result_xgb_P2_hard['Predicted_Score'].max() - grid_result_xgb_P2_hard['Predicted_Score'].min())\n",
    "    grid_result_xgb_P2_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/grid_result_xgb_reg_P2_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(grid_result_xgb_P2_hard['Real_Class'], grid_result_xgb_P2_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_grid_xgb_P2_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "print(PR_AUCs_grid_xgb_P1_hard)\n",
    "print(PR_AUCs_grid_xgb_P2_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49c519-2129-40dc-b6d7-495f87c793db",
   "metadata": {},
   "source": [
    "# **ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d5f75-91c4-4ac7-8330-e218142c0b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor  \n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "\n",
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(params):\n",
    "    # Create the ANN classifier with the given parameters\n",
    "    ann_grid = MLPRegressor(\n",
    "        hidden_layer_sizes=params['hidden_layer_sizes'],\n",
    "        activation=params['activation'],\n",
    "        solver=params['solver'],\n",
    "        alpha=params['alpha'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Perform 5-fold cross-validation and calculate mean squared error (MSE)\n",
    "    cv_scores = cross_val_score(ann_grid, X_grid_train, y_grid_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = np.mean(cv_scores)\n",
    "    \n",
    "    # Return the negative mean squared error as the loss\n",
    "    return {'loss': mean_mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'hidden_layer_sizes': hp.choice('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 100)]),\n",
    "    'activation': hp.choice('activation', ['relu', 'tanh', 'logistic']),\n",
    "    'solver': hp.choice('solver', ['adam', 'sgd', 'lbfgs']),\n",
    "    'alpha': hp.loguniform('alpha', -5, -1),  # L2 penalty parameter (e.g., from 0.00001 to 0.1)\n",
    "    'learning_rate': hp.choice('learning_rate', ['constant', 'adaptive', 'invscaling'])\n",
    "}\n",
    "\n",
    "# Run the optimization\n",
    "trials = Trials()\n",
    "best_params_ann_grid_reg_P1 = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  # Adjust the number of evaluations as needed\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(60) # Set random state for reproducibility\n",
    ")\n",
    "    \n",
    "# Save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_ann_grid_reg_P1.pkl\")\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(best_params_ann_grid_reg_P1, file)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print('Best hyperparameters:', best_params_ann_grid_reg_P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837983c-cf18-4685-ba0d-521326596a04",
   "metadata": {},
   "source": [
    "# **save the best hyperparameters found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc8ac587-7a4d-4688-bc82-19611f52bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best hyperparameters found\n",
    "file_path = (\"/home/juni/working/eman/results_reg/best_params_ann_grid_reg_P1.pkl\")\n",
    "with open(file_path, 'rb') as file:\n",
    "    best_params_ann_grid_reg_P1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0d51e9ad-449c-488e-bbc1-9482d27b7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the hyperparameter choices to the proper format\n",
    "if best_params_ann_grid_reg_P1['activation'] == 0:\n",
    "    best_params_ann_grid_reg_P1['activation'] = 'relu'\n",
    "elif best_params_ann_grid_reg_P1['activation'] == 1:\n",
    "    best_params_ann_grid_reg_P1['activation'] = 'tanh'\n",
    "else:\n",
    "    best_params_ann_grid_reg_P1['activation'] = 'logistic'\n",
    "\n",
    "\n",
    "\n",
    "# Convert the hyperparameter choices to the proper format\n",
    "if best_params_ann_grid_reg_P1['learning_rate'] == 0:\n",
    "    best_params_ann_grid_reg_P1['learning_rate'] = 'constant'\n",
    "elif best_params_ann_grid_reg_P1['learning_rate'] == 1:\n",
    "    best_params_ann_grid_reg_P1['learning_rate'] = 'adaptive'\n",
    "else:\n",
    "    best_params_ann_grid_reg_P1['learning_rate'] = 'invscaling'\n",
    "\n",
    "\n",
    "# Convert the hyperparameter choices to the proper format\n",
    "if best_params_ann_grid_reg_P1['solver'] == 0:\n",
    "    best_params_ann_grid_reg_P1['solver'] = 'adam'\n",
    "elif best_params_ann_grid_reg_P1['solver'] == 1:\n",
    "    best_params_ann_grid_reg_P1['solver'] = 'sgd'\n",
    "else:\n",
    "    best_params_ann_grid_reg_P1['solver'] = 'lbfgs'\n",
    "\n",
    "\n",
    "if best_params_ann_grid_reg_P1['hidden_layer_sizes'] == 0:\n",
    "    best_params_ann_grid_reg_P1['hidden_layer_sizes'] = (50,)\n",
    "elif best_params_ann_grid_reg_P1['hidden_layer_sizes'] == 1:\n",
    "    best_params_ann_grid_reg_P1['hidden_layer_sizes'] = (100,)\n",
    "elif best_params_ann_grid_reg_P1['hidden_layer_sizes'] == 2:\n",
    "    best_params_ann_grid_reg_P1['hidden_layer_sizes'] = (50,50)\n",
    "else:\n",
    "    best_params_ann_grid_reg_P1['hidden_layer_sizes'] = (100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30febe38-8f1a-414d-8606-afabffe541dd",
   "metadata": {},
   "source": [
    "# **train the ANN ten times and save the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a8dadbf1-2e35-499b-ab22-f389f6ab0874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3779, 0.3911, 0.4235, 0.4112, 0.4246, 0.4763, 0.4338, 0.3726, 0.4297, 0.3959]\n",
      "[0.3692, 0.4259, 0.3742, 0.3676, 0.4236, 0.3889, 0.3778, 0.3519, 0.4111, 0.3934]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor  \n",
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import pickle\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "PR_AUCs_grid_ann_P1_hard = []\n",
    "PR_AUCs_grid_ann_P2_hard = []\n",
    "for i in range(1,11):\n",
    "    ann_grid = MLPRegressor(\n",
    "    hidden_layer_sizes=best_params_ann_grid_reg_P1['hidden_layer_sizes'],\n",
    "    activation=best_params_ann_grid_reg_P1['activation'],\n",
    "    solver=best_params_ann_grid_reg_P1['solver'],\n",
    "    alpha=best_params_ann_grid_reg_P1['alpha'],\n",
    "    learning_rate=best_params_ann_grid_reg_P1['learning_rate'],\n",
    "    random_state=i)\n",
    "    \n",
    "    \n",
    "    # Fit the model\n",
    "    ann_grid.fit(X_grid_train, y_grid_train)\n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_ann_grid_score_P1_hard = ann_grid.predict(X_test_randomdecoys_grid_hard)\n",
    "  \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    grid_result_ann_P1_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_ann_grid_score_P1_hard,\n",
    "                                   \"Real_Score\": y_test_randomdecoys_grid_hard})\n",
    "    grid_result_ann_P1_hard['Predicted_Class'] = grid_result_ann_P1_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_ann_P1_hard['Real_Class'] = grid_result_ann_P1_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_ann_P1_hard['normalized_scores'] = (grid_result_ann_P1_hard['Predicted_Score'] - grid_result_ann_P1_hard['Predicted_Score'].min())/(grid_result_ann_P1_hard['Predicted_Score'].max() - grid_result_ann_P1_hard['Predicted_Score'].min())\n",
    "    grid_result_ann_P1_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/grid_result_ann_reg_P1_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(grid_result_ann_P1_hard['Real_Class'], grid_result_ann_P1_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_grid_ann_P1_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "    #Test the RF model on the test molecules:\n",
    "    prediction_test_ann_grid_score_P2_hard = ann_grid.predict(X_test_deepcoy_grid_hard)\n",
    " \n",
    "    \n",
    "    \n",
    "    # Get virtual screening results on the test molecules and export results to a csv file:\n",
    "    grid_result_ann_P2_hard = pd.DataFrame({\"Predicted_Score\": prediction_test_ann_grid_score_P2_hard,\n",
    "                                   \"Real_Score\": y_test_deepcoy_grid_hard})\n",
    "    grid_result_ann_P2_hard['Predicted_Class'] = grid_result_ann_P2_hard['Predicted_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_ann_P2_hard['Real_Class'] = grid_result_ann_P2_hard['Real_Score'].apply(lambda x: 'active' if x > 2 else 'inactive')\n",
    "    grid_result_ann_P2_hard['normalized_scores'] = (grid_result_ann_P2_hard['Predicted_Score'] - grid_result_ann_P2_hard['Predicted_Score'].min())/(grid_result_ann_P2_hard['Predicted_Score'].max() - grid_result_ann_P2_hard['Predicted_Score'].min())\n",
    "    grid_result_ann_P2_hard.to_csv(\"/home/juni/working/eman/revised_paper/hard_test_results/results_reg/grid_result_ann_reg_P2_hard_\"+str(i)+\".csv\")\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(grid_result_ann_P2_hard['Real_Class'], grid_result_ann_P2_hard['Predicted_Score'], pos_label='active')\n",
    "    pr_auc = round(auc(recall, precision),4)\n",
    "    PR_AUCs_grid_ann_P2_hard.append(pr_auc)\n",
    "    \n",
    "    \n",
    "print(PR_AUCs_grid_ann_P1_hard)\n",
    "print(PR_AUCs_grid_ann_P2_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab8cc5-7075-44e7-a33b-cb035f707017",
   "metadata": {},
   "source": [
    "# Generate train set with true actives and DeepCoy Decoys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "307b27a8-d685-4c07-bbf0-740b76dfada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_train_deepcoy = pd.concat([plec_train_true_actives,plec_train_deepcoy_decoys])\n",
    "grid_train_deepcoy = pd.concat([grid_train_true_actives,grid_train_deepcoy_decoys])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76bb602-1a91-46b2-b7f3-306db6533e47",
   "metadata": {},
   "source": [
    "# **Train and test the RF , XGB and ANN with above codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd74f7-a0df-4cd8-8aa5-301422eb1910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
